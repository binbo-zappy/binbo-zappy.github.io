

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Binbo">
  <meta name="keywords" content="">
  
    <meta name="description" content="ChatGPT对蒙特卡洛方法的介绍 蒙特卡洛方法是一类基于随机抽样和统计学原理的数值计算方法，其核心思想是通过随机抽样来近似解决问题。这种方法在强化学习、优化问题、概率估计等领域都有广泛的应用。以下是关于蒙特卡洛方法的一些基本概念：  基本思想  随机抽样： 蒙特卡洛方法利用随机抽样的方式来近似计算某个问题的数值解。通过大量的随机样本，可以得到对问题的概率分布、期望值等进行估计的结果。">
<meta property="og:type" content="article">
<meta property="og:title" content="2.1 蒙特卡洛估计">
<meta property="og:url" content="http://binbo-zappy.github.io/2024/12/04/DRL-%E7%8E%8B%E6%A0%91%E6%A3%AE/2-1-%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E4%BC%B0%E8%AE%A1/index.html">
<meta property="og:site_name" content="Binbo">
<meta property="og:description" content="ChatGPT对蒙特卡洛方法的介绍 蒙特卡洛方法是一类基于随机抽样和统计学原理的数值计算方法，其核心思想是通过随机抽样来近似解决问题。这种方法在强化学习、优化问题、概率估计等领域都有广泛的应用。以下是关于蒙特卡洛方法的一些基本概念：  基本思想  随机抽样： 蒙特卡洛方法利用随机抽样的方式来近似计算某个问题的数值解。通过大量的随机样本，可以得到对问题的概率分布、期望值等进行估计的结果。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://binbo-zappy.github.io/imgs/RL-WSS.png">
<meta property="article:published_time" content="2024-12-04T08:02:44.000Z">
<meta property="article:modified_time" content="2024-12-04T10:51:04.390Z">
<meta property="article:author" content="Binbo">
<meta property="article:tag" content="RL">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://binbo-zappy.github.io/imgs/RL-WSS.png">
  
  
  
  <title>2.1 蒙特卡洛估计 - Binbo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"binbo-zappy.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Binbo&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="2.1 蒙特卡洛估计"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-12-04 16:02" pubdate>
          2024年12月4日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          4.5k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          38 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">2.1 蒙特卡洛估计</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="chatgpt对蒙特卡洛方法的介绍">ChatGPT对蒙特卡洛方法的介绍</h1>
<p>蒙特卡洛方法是一类基于随机抽样和统计学原理的数值计算方法，其核心思想是通过随机抽样来近似解决问题。这种方法在强化学习、优化问题、概率估计等领域都有广泛的应用。以下是关于蒙特卡洛方法的一些基本概念：</p>
<ol type="1">
<li>基本思想
<ul>
<li><strong>随机抽样：</strong>
蒙特卡洛方法利用随机抽样的方式来近似计算某个问题的数值解。通过大量的随机样本，可以得到对问题的概率分布、期望值等进行估计的结果。</li>
</ul></li>
<li>应用领域
<ul>
<li><strong>强化学习：</strong>
在强化学习中，蒙特卡洛方法用于估计状态值、动作值，以及计算策略的期望回报。通过采样多条轨迹，可以近似地计算期望值。</li>
<li><strong>数值积分：</strong>
蒙特卡洛方法可以用于估计复杂函数的积分值。通过在函数定义域内随机采样，计算函数值的平均值，可以得到积分的近似值。</li>
<li><strong>概率估计：</strong>
蒙特卡洛方法在概率估计中也有应用，例如通过采样估计随机变量的期望、方差等统计量。</li>
</ul></li>
<li>算法步骤
<ol type="1">
<li><strong>随机抽样：</strong>
根据问题的特性，通过随机抽样生成一系列样本点。</li>
<li><strong>计算统计量：</strong>
对每个样本点进行计算，得到需要估计的统计量，例如期望值、方差等。</li>
<li><strong>平均估计：</strong>
对所有样本点计算的统计量进行平均，得到最终的近似解。</li>
</ol></li>
<li>优缺点
<ul>
<li><strong>优点：</strong>
蒙特卡洛方法是一种通用的数值计算方法，对于复杂问题具有很强的适应性。它不依赖于问题的具体形式，而是通过随机抽样来逼近解。</li>
<li><strong>缺点：</strong>
收敛速度相对较慢，特别是在维度较高的问题中，需要大量的样本才能获得准确的估计。同时，对于一些问题，可能存在抽样偏差。</li>
</ul></li>
</ol>
<p>总体而言，蒙特卡洛方法是一种强大的数值计算工具，尤其在面对复杂、高维度的问题时显示出其优越性。</p>
<p>蒙特卡洛(Monte Carlo) 是一大类随机算法(randomized algorithms)
的总称，它们通过随机样本来估算真实值。本节用几个例子讲解蒙特卡洛算法。</p>
<h1 id="例一近似pi值">例一：近似<span class="math inline">\(\pi\)</span>值</h1>
<p>我们都知道圆周率<span class="math inline">\(\pi\)</span>约等于
3.1415927。现在假装我们不知道<span class="math inline">\(\pi\)</span>,
而是要想办法近似估算<span class="math inline">\(\pi\)</span>值。假设我们有一个 (伪)
随机数生成器，我们能不能用随机样本来近似<span class="math inline">\(\pi\)</span>呢？这一小节讨论使用蒙特卡洛如何近似<span class="math inline">\(\pi\)</span>值。</p>
<p>假设我们有一个 (伪) 随机数生成器，可以均匀生成 -1 到 +1
之间的数。每次生成两个随机数，一个作为<span class="math inline">\(x\)</span>,另一个作为<span class="math inline">\(y\)</span>。于是每次生成了一个平面坐标系中的点<span class="math inline">\((x,y)\)</span>, 见图 2.3(左)。因为<span class="math inline">\(x\)</span>和<span class="math inline">\(y\)</span>都是在 ([-1,1])
区间上均匀分布，所以这个正方形内的点被抽到的概率是相同的。我们重复抽样<span class="math inline">\(n\)</span>次，得到了<span class="math inline">\(n\)</span>个正方形内的点。</p>
<p><img src="/2024/12/04/DRL-%E7%8E%8B%E6%A0%91%E6%A3%AE/2-1-%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E4%BC%B0%E8%AE%A1/b5c4792d8e806dea2de245eb613c8f50.png" srcset="/img/loading.gif" lazyload></p>
<p>如图2.3(右)所示，蓝色正方形里面包含一个绿色的圆，圆心是(0,0),半径等于1。刚才随机生成的<span class="math inline">\(n\)</span>个点有些落在圆外面，有些落在圆里面。</p>
<p>请问一个点落在圆里面的概率有多大呢？由于抽样是均匀的，因此这个概率显然是圆的面积与正方形面积的比值。正方形的面积是边长的平方，即<span class="math inline">\(a_1=2^2=4\)</span>。圆的面积是<span class="math inline">\(\pi \times
1^2=\pi\)</span>。那么一个点落在圆里面的概率就是<span class="math inline">\(p=\frac{a_2}{a_1}=\frac{\pi}{4}\)</span>。</p>
<p>设我们随机抽样了<span class="math inline">\(n\)</span>个点，设圆内的点的数量为随机变量<span class="math inline">\(M\)</span>。显然，<span class="math inline">\(M\)</span>的期望等于<span class="math inline">\(\mathbb{E}[M]=pn=\frac{\pi n}{4}\)</span>。</p>
<p>注意，这只是期望，并不是实际发生的结果。如果你抽<span class="math inline">\(n=5\)</span>个点，那么期望有<span class="math inline">\(\mathbb{E}[M]=\frac{5\pi}{4}\)</span>个点落在圆内。但实际观测值<span class="math inline">\(m\)</span>可能等于 0、1、2、3、4、5
中的任何一个。</p>
<p>给定一个点的坐标<span class="math inline">\((x,y)\)</span>,如何判断该点是否在圆内呢？已知圆心在原点，半径等于1,我们用一下圆的方程。如果<span class="math inline">\((x,y)\)</span>满足：<span class="math inline">\(x^2+y^2\leq1\)</span>,则说明<span class="math inline">\((x,y)\)</span>落在圆里面；反之，点就在圆外面。</p>
<p>我们均匀随机抽样得到<span class="math inline">\(n\)</span>个点，通过圆的方程对每个点做判别，发现有<span class="math inline">\(m\)</span>个点落在圆里面。如果<span class="math inline">\(n\)</span>非常大，那么随机变量<span class="math inline">\(M\)</span>的真实观测值<span class="math inline">\(m\)</span>就会非常接近期望<span class="math inline">\(\mathbb{E}[M]=\frac{\pi n}{4}\)</span>:</p>
<p><span class="math inline">\(m \approx \frac{\pi n}{4}.\)</span></p>
<p>由此得到：</p>
<p><span class="math inline">\(\pi \approx \frac{4m}{n}.\)</span></p>
<p>我们可以依据这个公式做编程实现。下面是伪代码：</p>
<ol type="1">
<li>初始化<span class="math inline">\(m=0\)</span>。用户指定样本数量<span class="math inline">\(n\)</span>的大小。<span class="math inline">\(n\)</span>越大，精度越高，但是计算量越大。</li>
<li>把下面的步骤重复<span class="math inline">\(n\)</span>次：(a).
从区间 ([-1,1]) 上做两次均匀随机抽样得到实数<span class="math inline">\(x\)</span>和<span class="math inline">\(y\)</span>。(b). 如果<span class="math inline">\(x^2+y^2\leq1\)</span>, 那么<span class="math inline">\(m \leftarrow m+1\)</span>。</li>
<li>返回<span class="math inline">\(\frac{4m}{n}\)</span>作为对<span class="math inline">\(\pi\)</span>的估计。</li>
</ol>
<p>大数定律保证了蒙特卡洛的正确性：当<span class="math inline">\(n\)</span>趋于无穷，<span class="math inline">\(\frac{4m}{n}\)</span>趋于<span class="math inline">\(\pi\)</span>。其实还能进一步用概率不等式分析误差的上界。比如使用
Bernstein 不等式，可以证明出下面结论：</p>
<p><span class="math inline">\(\left\|\frac{4m}{n}-\pi\right\|=O\left(\frac{1}{\sqrt{n}}\right).\)</span></p>
<p>这个不等式说明<span class="math inline">\(\frac{4m}{n}\)</span>(即对<span class="math inline">\(\pi\)</span>的估计) 会收敛到<span class="math inline">\(\pi\)</span>, 收敛率是<span class="math inline">\(\frac{1}{\sqrt{n}}\)</span>。然而这个收敛率并不快：样本数量<span class="math inline">\(n\)</span>增加一万倍，精度才能提高一百倍。</p>
<h1 id="例二估算阴影部分面积">例二：估算阴影部分面积</h1>
<p>图2.4中有正方形、圆、扇形，几个形状相交。请估算阴影部分面积。这个问题常见于初中数学竞赛。假如你不会微积分，也不会几何技巧，你是否有办法近似估算阴影部分面积呢？用蒙特卡洛可以很容易解决这个问题。</p>
<p><img src="/2024/12/04/DRL-%E7%8E%8B%E6%A0%91%E6%A3%AE/2-1-%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E4%BC%B0%E8%AE%A1/1733135856255-36277529-c6c9-4205-ad78-21f6c177226b.png" srcset="/img/loading.gif" lazyload></p>
<p>图 2.5 中绿色圆的圆心是 (1,1), 半径等于 1;蓝色扇形的圆心是
(0,0)、半径等于2。目的点<span class="math inline">\((x,y)\)</span>在绿色的圆中，而不在蓝色的扇形中。</p>
<p><img src="/2024/12/04/DRL-%E7%8E%8B%E6%A0%91%E6%A3%AE/2-1-%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E4%BC%B0%E8%AE%A1/4743c4dfdc896695524ef4a49289d47b.png" srcset="/img/loading.gif" lazyload></p>
<p>利用圆的方程可以判定点<span class="math inline">\((x,y)\)</span>是否在绿色圆里面。如果<span class="math inline">\((x,y)\)</span>满足方程<span class="math inline">\((x-1)^2+(y-1)^2\leq1\)</span>,</p>
<p>则说明<span class="math inline">\((x,y)\)</span>在绿色圆里面。</p>
<p>利用扇形的方程可以判定点<span class="math inline">\((x,y)\)</span>是否在蓝色扇形外面。如果点<span class="math inline">\((x,y)\)</span>满足方程</p>
<p><span class="math inline">\(x^2+y^2&gt;4\)</span>,</p>
<p>则说明<span class="math inline">\((x,y)\)</span>在蓝色扇形外面。</p>
<p>如果一个点同时满足方程 (2.1)和
(2.2),那么这个点一定在阴影区域内。从<span class="math inline">\([0,2]
\times [0,2]\)</span>这个正方形中做随机抽样，得到<span class="math inline">\(n\)</span>个点。然后用两个方程筛选落在阴影部分的点。</p>
<p>我们在正方形<span class="math inline">\([0,2] \times
[0,2]\)</span>中随机均匀抽样，得到的点有一定概率会落在阴影部分。我们来计算这个概率。正方形的边长等于2，所以面积<span class="math inline">\(a_1=4\)</span>。设阴影部分面积为<span class="math inline">\(a_2\)</span>。那么点落在阴影部分概率是</p>
<p><span class="math inline">\(p=\frac{a_2}{a_1}=\frac{a_2}{4}\)</span>。</p>
<p>我们从正方形中随机抽<span class="math inline">\(n\)</span>个点，设有<span class="math inline">\(M\)</span>个点落在阴影部分内(<span class="math inline">\(M\)</span>是个随机变量)。每个点落在阴影部分的概率是<span class="math inline">\(p\)</span>,所以<span class="math inline">\(M\)</span>的期望等于<span class="math inline">\(\mathbb{E}[M]=np=\frac{na_2}{4}\)</span>。</p>
<p>用方程 (2.1)和 (2.2) 对<span class="math inline">\(n\)</span>个点做筛选，发现实际上有<span class="math inline">\(m\)</span>个点落在阴影部分内 (<span class="math inline">\(m\)</span>是随机变量<span class="math inline">\(M\)</span>的观测值)。如果<span class="math inline">\(n\)</span>很大，那么<span class="math inline">\(m\)</span>会比较接近期望<span class="math inline">\(\mathbb{E}[M]=\frac{na_2}{4}\)</span>, 即<span class="math inline">\(m \approx \frac{na_2}{4}\)</span>。</p>
<p>也即<span class="math inline">\(a_2 \approx
\frac{4m}{n}\)</span>。</p>
<p>这个公式就是对阴影部分面积的估计。我们依据这个公式做编程实现。下面是伪代码：</p>
<ol type="1">
<li>初始化<span class="math inline">\(m=0\)</span>。用户指定样本数量<span class="math inline">\(n\)</span>的大小。<span class="math inline">\(n\)</span>越大，精度越高，但是计算量越大。</li>
<li>把下面的步骤重复<span class="math inline">\(n\)</span>次：(a).
从区间<span class="math inline">\([0,2]\)</span>上均匀随机抽样得到<span class="math inline">\(x\)</span>; 再做一次均匀随机抽样，得到<span class="math inline">\(y\)</span>。(b). 如果<span class="math inline">\((x-1)^2+(y-1)^2\leq1\)</span>和<span class="math inline">\(x^2+y^2&gt;4\)</span>两个不等式都成立，那么让<span class="math inline">\(m \leftarrow m+1\)</span>。</li>
<li>返回<span class="math inline">\(\frac{4m}{n}\)</span>作为对阴影部分面积的估计。</li>
</ol>
<h1 id="例三近似定积分">例三：近似定积分</h1>
<p>近似求积分是蒙特卡洛最重要的应用之一，在科学和工程中有广泛的应用。举个例子，给定一个函数：</p>
<p><span class="math inline">\(f(x)=\frac{1}{1+(\sin x)\cdot(\ln
x)^2},\)</span></p>
<p>要求计算<span class="math inline">\(f\)</span>在区间 0.8 到 3
上的定积分：</p>
<p><span class="math inline">\(I=\int_{0.8}^{3}f(x)dx.\)</span></p>
<p>有很多科学和工程问题需要计算定积分，而函数<span class="math inline">\(f(x)\)</span>可能很复杂，求定积分会很困难，甚至有可能不存在解析解。如果求解析解很困难，或者解析解不存在，则可以用蒙特卡洛近似计算数值解。</p>
<p><strong>一元函数的定积分</strong>
是相对比较简单的问题。一元函数的意思是变量<span class="math inline">\(x\)</span>是个标量。给定一元函数<span class="math inline">\(f(x)\)</span>, 求函数在<span class="math inline">\(a\)</span>到<span class="math inline">\(b\)</span>区间上的定积分：</p>
<p><span class="math inline">\(I=\int_{a}^{b}f(x)dx.\)</span></p>
<p>蒙特卡洛方法通过下面的步骤近似定积分：</p>
<ol type="1">
<li>在区间<span class="math inline">\([a,b]\)</span>上做随机抽样，得到<span class="math inline">\(n\)</span>个样本，记作：<span class="math inline">\(x_1,\cdots,x_n\)</span>。样本数量<span class="math inline">\(n\)</span>由用户自己定，<span class="math inline">\(n\)</span>越大，计算量越大，近似越准确。</li>
<li>对函数值<span class="math inline">\(f(x_1),\cdots,f(x_n)\)</span>求平均，再乘以区间长度<span class="math inline">\(b-a\)</span>:</li>
</ol>
<p><span class="math inline">\(q_n=(b-a)\cdot\frac{1}{n}\sum_{i=1}^{n}f(x_i).\)</span></p>
<ol start="3" type="1">
<li>返回<span class="math inline">\(q_n\)</span>作为定积分<span class="math inline">\(I\)</span>的估计值。</li>
</ol>
<p><strong>多元函数的定积分</strong> 要复杂一些。设<span class="math inline">\(f:\mathbb{R}^d\mapsto\mathbb{R}\)</span>是一个多元函数，变量<span class="math inline">\(x\)</span>是<span class="math inline">\(d\)</span>维向量。要求计算<span class="math inline">\(f\)</span>在集合<span class="math inline">\(\Omega\)</span>上的定积分：</p>
<p><span class="math inline">\(I=\int_{\Omega}f(\boldsymbol{x})d\boldsymbol{x}.\)</span></p>
<p>蒙特卡洛方法通过下面的步骤近似定积分：</p>
<ol type="1">
<li>在集合<span class="math inline">\(\Omega\)</span>上做均匀随机抽样，得到<span class="math inline">\(n\)</span>个样本，记作向量<span class="math inline">\(x_1,\cdots,x_n\)</span>。样本数量<span class="math inline">\(n\)</span>由用户自己定，<span class="math inline">\(n\)</span>越大，计算量越大，近似越准确。</li>
<li>计算集合<span class="math inline">\(\Omega\)</span>的体积：<span class="math inline">\(v=\int_{\Omega}d\boldsymbol{x}.\)</span></li>
<li>对函数值<span class="math inline">\(f(x_1),\cdots,f(x_n)\)</span>求平均，再乘以<span class="math inline">\(\Omega\)</span>的体积<span class="math inline">\(v\)</span>:</li>
</ol>
<p><span class="math inline">\(q_n=v\cdot\frac{1}{n}\sum_{i=1}^{n}f(x_i).\)</span>(2.3)</p>
<ol start="4" type="1">
<li>返回<span class="math inline">\(q_n\)</span>作为定积分<span class="math inline">\(I\)</span>的估计值。</li>
</ol>
<p>注意，算法第二步需要求<span class="math inline">\(\Omega\)</span>的体积。如果<span class="math inline">\(\Omega\)</span>是长方体、球体等规则形状，那么可以解析地算出体积<span class="math inline">\(v\)</span>。可是如果<span class="math inline">\(\Omega\)</span>是不规则形状，那么就需要定积分求<span class="math inline">\(\Omega\)</span>的体积<span class="math inline">\(v\)</span>,
这是比较困难的。可以用类似于上一小节“求阴影部分面积”的方法近似计算体积<span class="math inline">\(v\)</span>。</p>
<p>举例讲解多元函数的蒙特卡洛积分：这个例子中被积分的函数是二元函数：</p>
<p><span class="math inline">\(f(x,y)=\left\{\begin{array}{ll}1,&amp;\text{if
}x^2+y^2\leq1;\\0,&amp;\text{otherwise}.\end{array}\right.\)</span>(2.4)</p>
<p>直观地说，如果点<span class="math inline">\((x,y)\)</span>落在右图的绿色圆内，那么函数值就是
1; 否则函数值就是 0。定义集合<span class="math inline">\(\Omega=[-1,1]\times[-1,1]\)</span>,
即右图中蓝色的正方形，它的面积是<span class="math inline">\(v=4\)</span>。</p>
<p><img src="/2024/12/04/DRL-%E7%8E%8B%E6%A0%91%E6%A3%AE/2-1-%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E4%BC%B0%E8%AE%A1/1733136459845-bbf7be59-ef0e-451a-aed7-b19052789cd7.png" srcset="/img/loading.gif" lazyload></p>
<p>定积分<span class="math inline">\(I=\int_{\Omega}f(x,y)dxdy\)</span></p>
<p>等于多少呢？很显然，定积分等于圆的面积，即<span class="math inline">\(\pi \cdot 1^2=\pi\)</span>。因此，定积分<span class="math inline">\(I=\pi\)</span>。用蒙特卡洛求出<span class="math inline">\(I\)</span>,就得到了<span class="math inline">\(\pi\)</span>。从集合<span class="math inline">\(\Omega=[-1,1]\times[-1,1]\)</span>上均匀随机抽样<span class="math inline">\(n\)</span>个点，记作<span class="math inline">\((x_1,y_1),\cdots,(x_n,y_n)\)</span>。应用公式(2.3),
可得</p>
<p><span class="math inline">\(q_n=v\cdot\frac{1}{n}\sum_{i=1}^{n}f(x_i,y_i)=\frac{4}{n}\sum_{i=1}^{n}f(x_i,y_i).\)</span>(2.5)</p>
<p>把<span class="math inline">\(q_n\)</span>作为对定积分<span class="math inline">\(I=\pi\)</span>的近似。这与前面近似<span class="math inline">\(\pi\)</span>的算法完全相同，区别在于此处的算法是从另一个角度推导出的。</p>
<h1 id="例四近似期望">例四：近似期望</h1>
<p>蒙特卡洛还可以用来近似期望，这在整本书中会反复应用。设<span class="math inline">\(X\)</span>是<span class="math inline">\(d\)</span>维随机变量，它的取值范围是集合<span class="math inline">\(\Omega \subset \mathbb{R}^d\)</span>。函数<span class="math inline">\(p(x)\)</span>是<span class="math inline">\(X\)</span>的概率密度函数。设<span class="math inline">\(f:\Omega \mapsto
\mathbb{R}\)</span>是任意的多元函数，它关于变量<span class="math inline">\(X\)</span>的期望是：</p>
<p><span class="math inline">\(\mathbb{E}_{X\sim
p(\cdot)}\Big[f(X)\Big]=\int_{\Omega}p(x)\cdot f(x)d x.\)</span></p>
<p>由于期望是定积分，所以可以按照上一小节的方法，用蒙特卡洛求定积分。上一小节在集合<span class="math inline">\(\Omega\)</span>上做均匀抽样，用得到的样本近似上面公式中的定积分。</p>
<p>下面介绍一种更好的算法。既然我们知道概率密度函数<span class="math inline">\(p(x)\)</span>, 我们最好是按照<span class="math inline">\(p(x)\)</span>做非均匀抽样，而不是均匀抽样。按照<span class="math inline">\(p(x)\)</span>做非均匀抽样，可以比均匀抽样有更快的收敛。具体步骤如下：</p>
<ol type="1">
<li>按照概率密度函数<span class="math inline">\(p(x)\)</span>,在集合<span class="math inline">\(\Omega\)</span>上做非均匀随机抽样，得到<span class="math inline">\(n\)</span>个样本，记作向量<span class="math inline">\(x_1,\cdots,x_n \sim
p(\cdot)\)</span>。样本数量<span class="math inline">\(n\)</span>由用户自己定，<span class="math inline">\(n\)</span>越大，计算量越大；近似越准确。</li>
<li>对函数值<span class="math inline">\(f(x_1),\cdots,f(x_n)\)</span>求平均：</li>
</ol>
<p><span class="math inline">\(q_n=\frac{1}{n}\sum_{i=1}^{n}f(x_i).\)</span></p>
<ol start="3" type="1">
<li>返回<span class="math inline">\(q_n\)</span>作为期望<span class="math inline">\(\mathbb{E}_{X\sim
p(\cdot)}\Big[f(X)\Big]\)</span>的估计值。</li>
</ol>
<p>注 如果按照上述方式做编程实现，需要储存函数值<span class="math inline">\(f(x_1),\cdots,f(x_n)\)</span>。但用如下的方式做编程实现，可以减小内存开销。初始化<span class="math inline">\(q_0=0\)</span>。从<span class="math inline">\(t=1\)</span>到<span class="math inline">\(n\)</span>,依次计算</p>
<p><span class="math inline">\(q_t=(1-\frac{1}{t})\cdot
q_{t-1}+\frac{1}{t}\cdot f(x_t).\)</span>(2.6)</p>
<p>不难证明，这样得到的<span class="math inline">\(q_n\)</span>等于<span class="math inline">\(\frac{1}{n}\sum_{i=1}^{n}f(x_i)\)</span>。这样无需存储所有的<span class="math inline">\(f(x_1),\cdots,f(x_n)\)</span>。可以进一步把公式(2.6)
中的<span class="math inline">\(\frac{1}{t}\)</span>替换成<span class="math inline">\(\alpha_t\)</span>,得到公式：</p>
<p><span class="math inline">\(q_t=(1-\alpha_t)\cdot
q_{t-1}+\alpha_t\cdot f(x_t).\)</span></p>
<p>这个公式叫做 Robbins-Monro 算法，其中<span class="math inline">\(\alpha_n\)</span>称为学习步长或学习率。只要<span class="math inline">\(\alpha_t\)</span>满足下面的性质，就能保证算法的正确性：</p>
<p><span class="math inline">\(\lim_{n\to\infty}\sum_{t=1}^{n}\alpha_t=\infty\)</span>和<span class="math inline">\(\lim_{n\to\infty}\sum_{t=1}^{n}\alpha_t^2&lt;\infty.\)</span></p>
<p>显然，<span class="math inline">\(\alpha_t=\frac{1}{t}\)</span>满足上述性质。Robbins-Monro
算法可以应用在 Q 学习算法中。</p>
<h1 id="例五随机梯度">例五：随机梯度</h1>
<p>我们可以用蒙特卡洛近似期望来理解随机梯度算法。</p>
<p>设随机变量<span class="math inline">\(X\)</span>为一个数据样本，令<span class="math inline">\(w\)</span>为神经网络的参数。设<span class="math inline">\(p(x)\)</span>为随机变量<span class="math inline">\(X\)</span>的概率密度函数。定义损失函数<span class="math inline">\(L(X;w)\)</span>。它的值越小，意味着模型做出的预测越准确；反之，它的值越大，则意味着模型做出的预测越差。因此，我们希望调整神经网络的参数<span class="math inline">\(w\)</span>,
使得损失函数的期望尽量小。神经网络的训练可以定义为这样的优化问题：</p>
<p><span class="math inline">\(\min_{\boldsymbol{w}}\mathbb{E}_{X\sim
p(\cdot)}\Big[L(X;\boldsymbol{w})\Big].\)</span></p>
<p>目标函数<span class="math inline">\(\mathbb{E}_X[L(X;\boldsymbol{w})]\)</span>关于<span class="math inline">\(\boldsymbol{w}\)</span>的梯度是：</p>
<p><span class="math inline">\(\boldsymbol{g} \triangleq
\nabla_{\boldsymbol{w}}\mathbb{E}_{X\sim
p(\cdot)}\Big[L(X;\boldsymbol{w})\Big]=\mathbb{E}_{X\sim
p(\cdot)}\Big[\nabla_{\boldsymbol{w}}L(X;\boldsymbol{w})\Big].\)</span>(2.7)</p>
<p>可以做梯度下降更新<span class="math inline">\(\boldsymbol{w}\)</span>, 以减小目标函数<span class="math inline">\(\mathbb{E}_X[L(X;\boldsymbol{w})]\)</span>:</p>
<p><span class="math inline">\(\boldsymbol{w} \leftarrow \boldsymbol{w}
- \alpha \cdot \boldsymbol{g}.\)</span></p>
<p>此处的<span class="math inline">\(\alpha\)</span>被称作学习率
(learning rate)。直接计算梯度<span class="math inline">\(\boldsymbol{g}\)</span>通常会比较慢。为了加速计算，可以对期望</p>
<p><span class="math inline">\(\boldsymbol{g}=\mathbb{E}_{X\sim
p(\cdot)}\Big[\nabla_{\boldsymbol{w}}L(X;\boldsymbol{w})\Big]\)</span></p>
<p>做蒙特卡洛近似，把得到的近似梯度<span class="math inline">\(\tilde{\boldsymbol{g}}\)</span>称作随机梯度
(stochastic gradient), 用<span class="math inline">\(\tilde{\boldsymbol{g}}\)</span>代替<span class="math inline">\(\boldsymbol{g}\)</span>来更新<span class="math inline">\(\boldsymbol{w}\)</span>。</p>
<ol type="1">
<li>根据概率密度函数<span class="math inline">\(p(x)\)</span>做随机抽样，得到<span class="math inline">\(B\)</span>个样本，记作<span class="math inline">\(\tilde{x}_1,\ldots,\tilde{x}_B\)</span>。</li>
<li>计算梯度<span class="math inline">\(\nabla_{\boldsymbol{w}}L(\tilde{x}_j;\boldsymbol{w}),
\forall j=1,\ldots,B\)</span>。对它们求平均：</li>
</ol>
<p><span class="math inline">\(\tilde{\boldsymbol{g}}:=\frac{1}{B}\sum_{j=1}^{B}\nabla_{\boldsymbol{w}}L(\tilde{x}_j;\boldsymbol{w}).\)</span></p>
<p>我们称<span class="math inline">\(\tilde{\boldsymbol{g}}\)</span>为
<strong>随机梯度</strong>。因为<span class="math inline">\(\mathbb{E}[\tilde{\boldsymbol{g}}]=\boldsymbol{g}\)</span>,
它是<span class="math inline">\(\boldsymbol{g}\)</span>的一个无偏估计。</p>
<ol start="3" type="1">
<li>做随机梯度下降更新<span class="math inline">\(\boldsymbol{w}\)</span>:</li>
</ol>
<p><span class="math inline">\(\boldsymbol{w} \leftarrow \boldsymbol{w}
- \alpha \cdot \tilde{\boldsymbol{g}}.\)</span></p>
<p>样本数量<span class="math inline">\(B\)</span>称作批量大小 (batch
size), 通常是一个比较小的正整数，比如 1、8、16、32。所以我们称之为
<strong>最小批 (mini-batch) SGD</strong>。</p>
<p>在实际应用中，样本真实的概率密度函数<span class="math inline">\(p(x)\)</span>一般是未知的。在训练神经网络的时候，我们通常会收集一个训练数据集<span class="math inline">\(\mathcal{X}=\{x_1,\cdots,x_n\}\)</span>,
并求解这样一个经验风险最小化 (empirical risk minimization) 问题：</p>
<p><span class="math inline">\(\min_{\boldsymbol{w}}\frac{1}{n}\sum_{i=1}^{n}L(\boldsymbol{x}_i;\boldsymbol{w}).\)</span>(2.8)</p>
<p>这相当于我们用下面这个概率质量函数代替真实的<span class="math inline">\(p(x)\)</span>:</p>
<p><span class="math inline">\(p(x) =
\begin{cases}
\frac{1}{n}, &amp; \text{如果 } x \in \mathcal{X}; \\
0, &amp; \text{如果 } x \notin \mathcal{X}.
\end{cases}\)</span></p>
<p>公式的意思是随机变量<span class="math inline">\(X\)</span>的取值是<span class="math inline">\(n\)</span>个数据点中的一个，概率都是<span class="math inline">\(\frac{1}{n}\)</span>。那么最小批 SGD
的每一轮都从集合<span class="math inline">\(\{x_1,\cdots,x_n\}\)</span>中均匀随机抽取<span class="math inline">\(B\)</span>个样本，计算随机梯度，更新模型参数<span class="math inline">\(\boldsymbol{w}\)</span>。</p>
<h1 id="总结">总结</h1>
<p>本文详细讲解了蒙特卡洛的应用。其中最重要的知识点是蒙特卡洛近似期望：设<span class="math inline">\(X\)</span>是随机变量，<span class="math inline">\(x\)</span>是观测值，蒙特卡洛用<span class="math inline">\(f(x)\)</span>近似期望<span class="math inline">\(\mathbb{E}[f(X)]\)</span>。强化学习中的 Q
学习、SARSA、策略梯度等算法都需要这样用蒙特卡洛近似期望。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/AI/" class="category-chain-item">AI</a>
  
  
    <span>></span>
    
  <a href="/categories/AI/RL/" class="category-chain-item">RL</a>
  
  
    <span>></span>
    
  <a href="/categories/AI/RL/DRL-%E7%8E%8B%E6%A0%91%E6%A3%AE/" class="category-chain-item">DRL-王树森</a>
  
  

  

  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/RL/" class="print-no-link">#RL</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>2.1 蒙特卡洛估计</div>
      <div>http://binbo-zappy.github.io/2024/12/04/DRL-王树森/2-1-蒙特卡洛估计/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Binbo</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年12月4日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/12/04/DRL-%E7%8E%8B%E6%A0%91%E6%A3%AE/3-1-Random-Permutation/" title="3.1 随机排列">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">3.1 随机排列</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/12/04/DRL-%E7%8E%8B%E6%A0%91%E6%A3%AE/1-5-ALPHAGO/" title="1.5 ALPHAGO">
                        <span class="hidden-mobile">1.5 ALPHAGO</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
