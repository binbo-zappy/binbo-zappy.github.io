<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>1.5 计算机网络的性能指标</title>
    <link href="/2024/11/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/1-5-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9A%84%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87/"/>
    <url>/2024/11/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/1-5-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9A%84%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87/</url>
    
    <content type="html"><![CDATA[<h1 id="1-5-计算机网络的性能指标"><a href="#1-5-计算机网络的性能指标" class="headerlink" title="1.5 计算机网络的性能指标"></a>1.5 计算机网络的性能指标</h1><table><thead><tr><th align="center">指标</th><th align="left">评测</th></tr></thead><tbody><tr><td align="center">速率</td><td align="left">连接在计算机网络上的主机在数字信道上传送比特的速率，也称为比特率或数据率<br>bit&#x2F;s（b&#x2F;s，bps)，kb&#x2F;s，Mb&#x2F;s，Gb&#x2F;s</td></tr><tr><td align="center">带宽</td><td align="left">用来表示网络的通信线路所能传送数据的能力，单位为Hz<br>因此网络带宽表示在单位时间内从网络中的某一点到另一点所能通过的“最高数据量”<br>与速率指标相同</td></tr><tr><td align="center">吞吐量</td><td align="left">吞吐量表示在单位时间内通过某个网络（或信道、接口）的数据量。<br>吞吐量被经常用于对现实世界中的网络的一种测量，以便知道实际上到底有多少数据量能够通过网络。<br>吞吐量受网络的带宽或额定速率的限制。</td></tr><tr><td align="center">时延</td><td align="left">网络时延由三部分组成，分别为发送时延，传播时延，处理时延<br>网卡的发送速率，信道带宽，交换机的接口速率共同决定了发送时延<br><img src="/2024/11/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/1-5-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9A%84%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87/image-20241115211453147.png"></td></tr><tr><td align="center">时延带宽积</td><td align="left">1. 若发送端连续发送数据，则在所发送的第一个比特即将到达终点时，<br>     发送端就已经发送了时延带宽积个比特。<br>2. 链路的时延带宽积又称为以比特为单位的链路长度。</td></tr><tr><td align="center">往返时间（RTT）</td><td align="left">双向交互一次所需的时间<br>从源主机发送分组开始，直到源主机收到来自目的主机的确认分组为止</td></tr><tr><td align="center">利用率</td><td align="left">分为信道利用率，网络利用率<br>信道利用率：表示某信道有百分之几的时间是被利用的<br>网络利用率：全网络的信道利用率加权平均<br>信道利用率并非越高越好，高利用率会引发高时延</td></tr><tr><td align="center">丢包率</td><td align="left">丢包率即分组丢失率，是指在一定的时间范围内，传输过程中丢失的分组数量与总分组数量的比率。<br>丢包率具体可分为接口丢包率、结点丢包率、链路丢包率、路径丢包率、网络丢包率等<br></td></tr></tbody></table><ol><li><p>补充</p><ol><li>时延计算公式</li></ol></li></ol><p>$$<br>发送时延 &#x3D; \frac{分组长度}{发送速率}\\<br>$$</p><p>$$<br>发送时延 &#x3D; \frac{信道长度}{电磁波传播速率}<br>$$</p><ol start="2"><li>时延带宽积</li></ol><p>$$<br>时延带宽积 &#x3D; 传播时延 \times 带宽<br>$$</p><ul><li>处理时延一般不计算</li></ul><ol start="3"><li><p>网络当前时延与信道利用率之间的关系<br>$$<br>D为网络当前时延，D_0为网络空闲时的时延，U为信道利用率\<br>$$</p></li><li><p>丢包率计算公式<br>$$<br>丢包率 &#x3D; \frac{一定时间范围内丢失的分组数量}{总分组数量}<br>$$</p><p>$$<br>D &#x3D; \frac{D_0}{1-U}<br>$$</p></li><li><p>分组丢失的两种情况</p><ol><li>分组在传输过程中出现误码，被结点丢弃</li><li>分组到达一台队列已满的分组交换机时被丢弃，在通信量较大时就可能造成网络拥塞。</li></ol></li><li><p>丢包率反映了网络的拥塞情况</p><ol><li>无拥塞时路径丢包率为0</li><li>轻度拥塞时路径丢包率为1%~4%</li><li>严重拥塞时路径丢包率为5%~15%</li></ol></li><li><p>n个分组，m段链路，忽略处理时延，总时延的计算（假设分组等长，各链路长度相同，带宽相同）<br>$$<br>总时延 &#x3D; n个分组的发送时延 + 1个分组的发送时延 \times (m-1) + 1段链路的传播时延 \times m<br>$$</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>计算机基础</category>
      
      <category>计算机网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>计算机网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>1.4 计算机网络的定义和分类</title>
    <link href="/2024/11/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/1-4-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AE%9A%E4%B9%89%E5%92%8C%E5%88%86%E7%B1%BB/"/>
    <url>/2024/11/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/1-4-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AE%9A%E4%B9%89%E5%92%8C%E5%88%86%E7%B1%BB/</url>
    
    <content type="html"><![CDATA[<h1 id="1-4-计算机网络的定义和分类"><a href="#1-4-计算机网络的定义和分类" class="headerlink" title="1.4 计算机网络的定义和分类"></a>1.4 计算机网络的定义和分类</h1><h2 id="1-定义"><a href="#1-定义" class="headerlink" title="1. 定义"></a>1. 定义</h2><ol><li><p>简单定义：一些<strong>互相连接</strong>的，<strong>自治</strong>的计算机的<strong>集合</strong></p><blockquote><p>互连：是指计算机之间可以通过有线或无线的方式进行数据通信；<br>自治：是指独立的计算机，它有自己的硬件和软件，可以单独运行使用；<br>集合：是指至少需要两台计算机。</p></blockquote></li><li><p>计算机网络的较好的定义</p><blockquote><p>计算机网络主要是由一些通用的、可编程的硬件互连而成的，而这些硬件并非专门用来实现某一特定目的（例如，传送数据或视频信号)。这些可编程的硬件能够用来传送多种不同类型的数据，并能支持广泛的和日益增长的应用。</p></blockquote><ol><li>计算机网络所连接的硬件，并不限于一般的计算机，而是包括了智能手机等智能硬件</li><li>计算机网络并非专门用来传送数据，而是能够支持很多种的应用（包括今后可能出现的名种应用)</li></ol></li></ol><h2 id="2-分类"><a href="#2-分类" class="headerlink" title="2. 分类"></a>2. 分类</h2><h3 id="2-1-按交换技术分类"><a href="#2-1-按交换技术分类" class="headerlink" title="2.1 按交换技术分类"></a>2.1 按交换技术分类</h3><ol><li>电路交换网路</li><li>报文交换网络</li><li>分组交换网络</li></ol><h3 id="2-2-按使用者分类"><a href="#2-2-按使用者分类" class="headerlink" title="2.2 按使用者分类"></a>2.2 按使用者分类</h3><ol><li><p>公用网</p><blockquote><p>电信公司出资建造,给电信公司缴纳费用即可使用</p></blockquote></li><li><p>专用网</p><blockquote><p>不向外人提供服务</p></blockquote></li></ol><h3 id="2-3-按传输介质分类"><a href="#2-3-按传输介质分类" class="headerlink" title="2.3 按传输介质分类"></a>2.3 按传输介质分类</h3><ol><li><p>有线网路</p><blockquote><p>包括双绞线网络,光纤网络等</p></blockquote></li><li><p>无线网络</p><blockquote><p>WIFI应用普遍</p></blockquote></li></ol><h3 id="2-4-按覆盖范围分类"><a href="#2-4-按覆盖范围分类" class="headerlink" title="2.4 按覆盖范围分类"></a>2.4 按覆盖范围分类</h3><ol><li><p>广域网(WAN)</p><blockquote><p>可以覆盖一个国家,地区甚至几个洲</p><p>WAN是因特网的核心部分,为核心路由器提供远距离高速连接</p></blockquote></li><li><p>城域网(MAN)</p><blockquote><p>覆盖一个街区,或几个城市</p><p>通常作为城市骨干网,互连学校,企业,机构的局域网</p></blockquote></li><li><p>局域网(LAN)</p><blockquote><p>覆盖一个实验室,一幢楼,一个校园等</p></blockquote></li><li><p>个域网(PAN)</p><blockquote><p>即无线个人区域网(WPAN),在各人工作的地方,将属于个人使用的电子设备用无线技术连接起来的网络</p></blockquote></li></ol><h3 id="2-5-按拓扑结构分类"><a href="#2-5-按拓扑结构分类" class="headerlink" title="2.5 按拓扑结构分类"></a>2.5 按拓扑结构分类</h3><ol><li>总线型网络</li></ol><p><img src="/2024/11/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/1-4-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AE%9A%E4%B9%89%E5%92%8C%E5%88%86%E7%B1%BB/image-20230712140101315.png"></p><ol start="2"><li>星型网络</li></ol><p><img src="/2024/11/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/1-4-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AE%9A%E4%B9%89%E5%92%8C%E5%88%86%E7%B1%BB/image-20230712140145867.png"></p><ol start="3"><li>环型网络</li></ol><p><img src="/2024/11/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/1-4-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AE%9A%E4%B9%89%E5%92%8C%E5%88%86%E7%B1%BB/image-20230712140251758.png"></p><ol start="4"><li>网状型网络</li></ol><p><img src="/2024/11/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/1-4-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AE%9A%E4%B9%89%E5%92%8C%E5%88%86%E7%B1%BB/image-20230712140454142.png"></p>]]></content>
    
    
    <categories>
      
      <category>计算机基础</category>
      
      <category>计算机网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>计算机网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>1.3 三种交换方式</title>
    <link href="/2024/11/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/1-3-%E4%B8%89%E7%A7%8D%E4%BA%A4%E6%8D%A2%E6%96%B9%E5%BC%8F/"/>
    <url>/2024/11/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/1-3-%E4%B8%89%E7%A7%8D%E4%BA%A4%E6%8D%A2%E6%96%B9%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<h1 id="1-3-三种交换方式"><a href="#1-3-三种交换方式" class="headerlink" title="1.3 三种交换方式"></a>1.3 三种交换方式</h1><h2 id="1-电路交换-Circuit-Switching"><a href="#1-电路交换-Circuit-Switching" class="headerlink" title="1. 电路交换(Circuit Switching)"></a>1. 电路交换(Circuit Switching)</h2><ul><li>电话交换机接通电话线的方式称为电路交换，中间设备是电话交换机</li><li>从通信资源的分配角度来看，交换(Switching)就是按照某种方式动态地分配传输线路的资源；</li><li>当使用电路交换来传送计算机数据时，其线路的传输效率往往很低。</li><li>不适合计算机传输数据，因为占用通信资源，却迟迟不使用，造成通信资源的浪费</li></ul><p><img src="/2024/11/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/1-3-%E4%B8%89%E7%A7%8D%E4%BA%A4%E6%8D%A2%E6%96%B9%E5%BC%8F/image-20241115203653573.png" alt="电话交换机"></p><ol><li>电话交换的三个步骤<ol><li>建立连接（分配通信资源）</li><li>通话（一直占用通信资源）</li><li>释放连接（归还通信资源）</li></ol></li><li>优点<ol><li>通信时延小</li><li>有序传输</li><li>没有冲突</li><li>适用范围广</li><li>实时性强</li><li>控制简单</li></ol></li><li>缺点<ol><li>建立连接时间长</li><li>线路独占，使用效率低</li><li>灵活性差</li><li>难以规格化</li></ol></li></ol><h2 id="2-分组交换-Packet-Switching-※"><a href="#2-分组交换-Packet-Switching-※" class="headerlink" title="2. 分组交换(Packet Switching)※"></a>2. 分组交换(Packet Switching)※</h2><p><img src="/2024/11/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/1-3-%E4%B8%89%E7%A7%8D%E4%BA%A4%E6%8D%A2%E6%96%B9%E5%BC%8F/image-20241115204514266.png"></p><blockquote><p>通常把表示消息的整块数据称为一个报文</p></blockquote><ol><li><p>步骤</p><ol><li><p>发送方：构造分组，发送分组</p></li><li><p>路由器：缓存分组，转发分组</p></li><li><p>接收方：接收分组，还原报文</p></li></ol></li><li><p>优点</p><ol><li>无需建立连接</li><li>线路利用率高</li><li>简化了存储管理</li><li>加速传输</li><li>减少出错概率和重发数据量</li></ol></li><li><p>缺点</p><ol><li><p>引起了转发时延</p></li><li><p>需要传输额外的信息量</p></li><li><p>对于数据报服务，存在失序、丢失或重复分组的问题;</p><p>对于虚电路服务存在呼叫建立、数据传输和虚电路释放三个过程</p></li></ol></li></ol><h2 id="3-报文交换-Message-Switching"><a href="#3-报文交换-Message-Switching" class="headerlink" title="3. 报文交换(Message Switching)"></a>3. 报文交换(Message Switching)</h2><blockquote><p>与分组交换类似，但对报文大小没有限制，也不分组，现代已很少使用该方法</p></blockquote><ol><li><p>优点</p><ol><li>无需建立连接</li><li>动态分配线路</li><li>提高线路可靠性</li><li>提高线路利用率</li><li>提供多目标服务</li></ol></li><li><p>缺点</p><ol><li>引起了转发时延</li><li>需要较大存储缓存空间</li><li>需要传输额外的信息量</li></ol></li></ol><p><img src="/2024/11/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/1-3-%E4%B8%89%E7%A7%8D%E4%BA%A4%E6%8D%A2%E6%96%B9%E5%BC%8F/image-20241115204815895.png"></p>]]></content>
    
    
    <categories>
      
      <category>计算机基础</category>
      
      <category>计算机网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>计算机网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HCTA：多智能体强化学习中的分层合作任务分配</title>
    <link href="/2024/11/15/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1%E5%88%86%E9%85%8D/HCTA%EF%BC%9A%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%88%86%E5%B1%82%E5%90%88%E4%BD%9C%E4%BB%BB%E5%8A%A1%E5%88%86%E9%85%8D/"/>
    <url>/2024/11/15/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1%E5%88%86%E9%85%8D/HCTA%EF%BC%9A%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%88%86%E5%B1%82%E5%90%88%E4%BD%9C%E4%BB%BB%E5%8A%A1%E5%88%86%E9%85%8D/</url>
    
    <content type="html"><![CDATA[<h1 id="HCTA-Hierarchical-Cooperative-Task-Allocation-in-Multi-Agent-Reinforcement-Learning"><a href="#HCTA-Hierarchical-Cooperative-Task-Allocation-in-Multi-Agent-Reinforcement-Learning" class="headerlink" title="HCTA:Hierarchical Cooperative Task Allocation in Multi-Agent Reinforcement Learning"></a>HCTA:Hierarchical Cooperative Task Allocation in Multi-Agent Reinforcement Learning</h1><h2 id="1-主要内容"><a href="#1-主要内容" class="headerlink" title="1. 主要内容"></a>1. 主要内容</h2><ol><li><strong>子任务选择</strong>：</li></ol><ul><li>基于行动链的长期行为特征动态选择每个智能体适合的子任务。</li></ul><ol start="2"><li><strong>层次化策略学习</strong>：</li></ol><ul><li>结合上述子任务分解和选择，形成层次化合作策略学习框架。在上层动态选择子任务，并在下层根据上层的任务分配结果指导具体决策策略的学习。</li></ul><ol start="3"><li><strong>双时序分辨率框架</strong>：</li></ol><ul><li>HCTA使用双时序分辨率框架，在低时序分辨率的时标上进行任务选择，然后在高时序分辨率的时标上进行策略学习。</li></ul><ol start="4"><li><strong>实验验证</strong>：</li></ol><ul><li>在StarCraft II环境中进行广泛的实验，以评估HCTA框架在不同难度级别上的表现，并与其他基线算法进行比较。</li></ul><p>这些方法共同构成了文章提出的HCTA框架，旨在通过层次化和动态的任务分配来提高多智能体系统在复杂任务中的合作效率和学习效果。</p><ul><li>在本文中，我们的目标是使<strong>个体的子组能够通过人类在处理复杂任务时使用的分解思想来学习解决不同的子任务。</strong></li></ul><h2 id="2-子任务分解"><a href="#2-子任务分解" class="headerlink" title="2. 子任务分解"></a>2. 子任务分解</h2><p>在文章中提到的HCTA（Hierarchical Cooperative Task Allocation）框架中，子任务的分解是通过以下步骤实现的：</p><ol><li><strong>行动表示学习（Action Representation Learning）</strong>：</li></ol><ul><li>首先，框架通过行动表示学习来实现子任务的分解。这是通过创建一个能够反映行动对环境和其他智能体影响的表示（即<code>za = fθ(a; θe)</code>）来完成的，其中<code>za</code>是行动的表示，<code>a</code>是行动本身，<code>θ</code>是学习到的参数。</li></ul><ol start="2"><li><strong>行动空间聚类（Action Space Clustering）</strong>：</li></ol><ul><li>基于行动表示的结果，整个行动空间被聚类分解为多个子行动空间，每个子行动空间对应一个子任务。这样的分解减少了每个子任务的行动空间维度，使得相应的智能体在具有相似效果的行动空间中搜索。</li></ul><ol start="3"><li><strong>行动链模型（Action Chain Model）</strong>：</li></ol><ul><li>使用行动链模型来学习行动编码器。每个智能体选择多个时间步的行动表示作为行动链编码器的输入。通过自注意力机制，智能体学习与自身属性相关的多步行动的累积效应。</li></ul><ol start="4"><li><strong>子任务定义（Subtask Definition）</strong>：</li></ol><ul><li>文章中对子任务的定义是：对于一个给定的合作多智能体任务<code>G</code>，一个角色<code>ρi</code>是一个包含子任务<code>ϕi</code>的元组，<code>ϕi</code>由<code>⟨Ai, Ii, S, P, R, Ωi, O, γ⟩</code>组成，其中<code>Ai</code>是子任务的行动空间，<code>Ii</code>是智能体的子集，且满足<code>Ii ⊂ I</code>，<code>∪iIi = I</code>，<code>Ii ∩ Ij = ∅</code>（对于<code>i ≠ j</code>）。</li></ul><ol start="5"><li><strong>长期行为链（Long-term Behavior Chain）</strong>：</li></ol><ul><li>基于行动链的结果，生成反映智能体行为特征的长期行动链。这个长期行为链用于动态选择适合每个智能体的子任务。</li></ul><p>通过这些步骤，HCTA框架能够将复杂的多智能体任务分解为更小、更易于管理的子任务，每个子任务都涉及一个较小的行动观察空间，从而使智能体能够更有效地专注于特定的子任务。这种分解方法不仅提高了任务分配的效率，还降低了计算复杂度，并使得智能体能够更好地协作以完成复杂的任务。</p>]]></content>
    
    
    <categories>
      
      <category>科研</category>
      
      <category>多智能体强化学习任务分配</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RL</tag>
      
      <tag>科研</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>面向兵棋推演的强化学习分层任务优化技术研究</title>
    <link href="/2024/11/15/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1%E5%88%86%E9%85%8D/%E9%9D%A2%E5%90%91%E5%85%B5%E6%A3%8B%E6%8E%A8%E6%BC%94%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%88%86%E5%B1%82%E4%BB%BB%E5%8A%A1%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/"/>
    <url>/2024/11/15/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1%E5%88%86%E9%85%8D/%E9%9D%A2%E5%90%91%E5%85%B5%E6%A3%8B%E6%8E%A8%E6%BC%94%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%88%86%E5%B1%82%E4%BB%BB%E5%8A%A1%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/</url>
    
    <content type="html"><![CDATA[<h2 id="1-主要内容"><a href="#1-主要内容" class="headerlink" title="1. 主要内容"></a>1. 主要内容</h2><p>论文深入探讨了分层控制结构的多智能体强化学习算法在兵棋推演环境中的应用，旨在优化复杂和不确定环境下的任务分配和多智能体任务的执行过程。主要研究内容包括：</p><ol><li>针对实时兵棋推演环境，设计了兵棋AI的状态空间和动作空间，并生成了敌我对抗态势的关键特征信息。通过离散化连续动作的操作优化了原始动作空间，简化了多智能体的交互过程，加快了网络学习速度。</li><li>提出了一种融合注意力机制的DQN算法（ADQN），通过嵌入网络和注意力对输入进行向量化处理后输入DQN网络，将环境分解为独立的子环境，并重新定义特定于子任务的动作-价值函数，有效提高了在复杂环境中进行任务分配的质量和效率。</li><li>基于深度强化学习的多级控制结构，提出了多智能体分层自主决策算法（ADQN-MAPPO），结合了多智能体近端策略优化算法与ADQN算法，通过将复杂任务划分成子任务进行分配后再执行，增强了智能体自主决策的能力，提高了算法模型的训练速度和决策能力。</li></ol><p>论文通过在山地3v3和水田3v3的兵棋推演环境中的实验，验证了ADQN-MAPPO算法在得分能力、胜率、步均推理时间以及模型的泛化能力等方面的优越性能。研究结果对进一步提升分层控制结构的多智能体强化学习算法在兵棋推演以及其他复杂应用环境中的性能和应用范围提供了参考意义。</p><h2 id="2-分层决策框架"><a href="#2-分层决策框架" class="headerlink" title="2. 分层决策框架"></a>2. 分层决策框架</h2><p>这篇论文中提出的分层决策框架是为了解决兵棋推演环境中的多智能体任务分配和执行问题。分层决策框架包括两个主要层次：任务分配层和智能体决策层。以下是这两个层次的详细介绍：</p><h3 id="2-1-任务分配层"><a href="#2-1-任务分配层" class="headerlink" title="2.1 任务分配层"></a>2.1 任务分配层</h3><p>任务分配层的目的是将全局任务分解为多个子任务，并将这些子任务分配给不同的智能体。这一层主要关注如何在多智能体系统中高效地分配任务，以便每个智能体可以专注于自己的子任务，从而提高整体任务执行的效率和效果。</p><ul><li><strong>状态空间和动作空间设计</strong>：在这一层中，状态空间包括了整个环境的总体状态，如战场上的地形、敌我双方的兵力部署等。动作空间则由子任务的编号集合构成，意味着每个智能体的动作是选择一个子任务来执行。</li><li><strong>子任务设计</strong>：根据兵棋推演游戏的特性，将总体任务细分为行军、进攻、防御、支援、夺控等子任务。每个子任务由任务名称、编号、类型、关系、目标等元素组成。</li><li><strong>ADQN算法</strong>：提出了一种融合注意力机制的DQN算法（ADQN），用于处理任务分配问题。ADQN算法通过智能体对子任务的执行，将环境分解为独立的子环境，并重新定义特定于子任务的动作-价值函数。</li></ul><h3 id="2-2-智能体决策层"><a href="#2-2-智能体决策层" class="headerlink" title="2.2 智能体决策层"></a>2.2 智能体决策层</h3><p>智能体决策层根据任务分配层分配的子任务，每个智能体需要做出具体的行动决策来完成任务。这一层主要关注智能体如何在局部环境中做出最优决策。</p><ul><li><strong>MAPPO算法</strong>：在这一层中，使用了多智能体近端策略优化算法（MAPPO），它是一种适用于多智能体环境的强化学习算法，可以处理分布式部分可观察马尔可夫决策过程（DEC-POMDP）。</li><li><strong>策略网络和评价网络</strong>：每个智能体都有自己的策略网络，根据局部观测信息产生动作。同时，有一个全局评价网络根据全局环境信息生成状态价值，用于指导策略网络的更新。</li><li><strong>分层架构的优势</strong>：通过分层架构，上层任务分配网络可以在更大的时间尺度上运行，而下层智能体策略网络则在更细的尺度上做出决策。这种分层方法有助于提高智能体在兵棋推演环境中的决策效率和效果。</li></ul><h3 id="2-3-ADQN-MAPPO算法"><a href="#2-3-ADQN-MAPPO算法" class="headerlink" title="2.3 ADQN-MAPPO算法"></a>2.3 ADQN-MAPPO算法</h3><p>ADQN-MAPPO算法是将ADQN算法和MAPPO算法结合的分层决策框架。这种框架通过将复杂任务分解为子任务，并在不同的抽象层次上学习策略，解决了大规模复杂环境下的决策问题。ADQN-MAPPO算法在实验中表现出了优越的性能，包括更高的得分能力、胜率以及更快的收敛速度。</p>]]></content>
    
    
    <categories>
      
      <category>科研</category>
      
      <category>多智能体强化学习任务分配</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RL</tag>
      
      <tag>科研</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于分层强化学习的多智能体博弈对抗策略 todo</title>
    <link href="/2024/11/15/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1%E5%88%86%E9%85%8D/%E5%9F%BA%E4%BA%8E%E5%88%86%E5%B1%82%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%8D%9A%E5%BC%88%E5%AF%B9%E6%8A%97%E7%AD%96%E7%95%A5/"/>
    <url>/2024/11/15/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1%E5%88%86%E9%85%8D/%E5%9F%BA%E4%BA%8E%E5%88%86%E5%B1%82%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%8D%9A%E5%BC%88%E5%AF%B9%E6%8A%97%E7%AD%96%E7%95%A5/</url>
    
    <content type="html"><![CDATA[<h2 id="1-主要内容"><a href="#1-主要内容" class="headerlink" title="1. 主要内容"></a>1. 主要内容</h2><h3 id="1-1-研究内容"><a href="#1-1-研究内容" class="headerlink" title="1.1 研究内容"></a>1.1 研究内容</h3><ul><li>提出了一种结合任务可解释性的指挥官-集群多智能体分层强化学习算法，提高算法在复杂博弈场景中的收敛速度。</li><li>设计了一种结合软决策树的多智能体分层强化学习算法，增强了策略的解释性。</li><li>基于模糊决策树建立了博弈对抗策略，通过挖掘战法规则，模拟人的决策过程。</li><li>在联合作战实验平台上设计了空战博弈场景和海空联合作战场景，验证了所提算法的有效性。</li></ul><h3 id="1-2-算法设计与实验验证"><a href="#1-2-算法设计与实验验证" class="headerlink" title="1.2 算法设计与实验验证"></a>1.2 算法设计与实验验证</h3><ul><li>设计了指挥官-集群分层强化学习算法，并通过实验验证了其在收敛性、解释性与作战效能方面的优势。</li><li>设计了结合软决策树的分层强化学习算法，验证了其在策略解释性和算法收敛性方面的优势。</li><li>提出了基于模糊决策树的博弈对抗策略，并通过实验验证了其分类效果和战法规则提取效果。</li></ul><h3 id="1-3-实验环境与设置"><a href="#1-3-实验环境与设置" class="headerlink" title="1.3 实验环境与设置"></a>1.3 实验环境与设置</h3><ul><li>使用了“StarCraft2”作为实验平台，设计了多种博弈场景，包括简单同构智能体控制场景、复杂同构智能体控制场景和复杂异构智能体控制场景。</li></ul><h3 id="1-4-结论与展望"><a href="#1-4-结论与展望" class="headerlink" title="1.4 结论与展望"></a>1.4 结论与展望</h3><ul><li>论文提出的分层强化学习算法在多智能体博弈对抗中具有实际应用价值和潜力，尤其在提高指挥部快速决策能力和军队快速反应打击能力上。</li><li>论文还指出了研究的局限性，并对未来的研究方向提出了展望，包括消除上层智能体学习训练结果对模型性能的负面影响，以及针对模糊环境下多层次、多目标的决策问题开展研究。</li></ul><h2 id="2-研究方法"><a href="#2-研究方法" class="headerlink" title="2. 研究方法"></a>2. 研究方法</h2><ul><li><strong>分层强化学习（HRL）</strong>：文章采用分层强化学习方法来处理多智能体复杂博弈场景中的策略优化问题。这种方法通过将复杂的决策问题分解为多个层次，使得学习过程更加高效和可解释。</li><li><strong>结合任务可解释性</strong>：文章提出了结合任务可解释性的指挥官-集群分层强化学习算法，通过模仿学习设计可解释的子任务，引入专家经验，提高算法的收敛速度。</li><li><strong>软决策树</strong>：为了增强策略的解释性，文章设计了结合软决策树的分层强化学习算法，通过引入线性权重表示状态特征与决策结果之间的因果逻辑。</li><li><strong>模糊决策树</strong>：文章进一步挖掘战法规则，建立基于模糊决策树的博弈对抗策略，模拟人的决策过程，并提取模糊决策树中隐藏的战术规则。</li></ul><h2 id="3-算法实现"><a href="#3-算法实现" class="headerlink" title="3. 算法实现"></a>3. 算法实现</h2><ul><li><strong>指挥官-集群分层强化学习算法（HES）</strong>：文章实现了一种指挥官-集群分层强化学习算法，该算法包含上层指挥官决策模型和下层集群作战模型，通过可解释子任务实现信息传递。</li><li><strong>结合软决策树的分层强化学习算法（HEE）</strong>：文章实现了一种结合软决策树的分层强化学习算法，该算法在HES算法框架基础上，将软决策树结构融入宏观决策过程中。</li><li><strong>基于模糊决策树的博弈对抗策略（FDTGAS）</strong>：文章实现了一种基于模糊决策树的博弈对抗策略，通过预处理对抗数据，构建模糊决策树，并从中提取战法规则。</li></ul><h2 id="4-上层决策模型的主要特点和实现细节："><a href="#4-上层决策模型的主要特点和实现细节：" class="headerlink" title="4. 上层决策模型的主要特点和实现细节："></a>4. 上层决策模型的主要特点和实现细节：</h2><h3 id="4-1-指挥官-集群分层强化学习算法（HES）中的上层决策模型"><a href="#4-1-指挥官-集群分层强化学习算法（HES）中的上层决策模型" class="headerlink" title="4.1 指挥官-集群分层强化学习算法（HES）中的上层决策模型"></a>4.1 指挥官-集群分层强化学习算法（HES）中的上层决策模型</h3><ul><li><strong>指挥官决策模型</strong>：模拟战争中高级指挥官的决策过程，基于战争总体形势的变化制定总体作战规划，并将战斗子任务分配给下层战斗单位。</li><li><strong>任务可解释性</strong>：结合任务可解释性思想，设计可解释的子任务，将专家经验引入到分层框架中，引导智能体进行定向学习，提高算法的收敛速度。</li></ul><h3 id="4-2-结合软决策树的分层强化学习算法（HEE）中的上层决策模型"><a href="#4-2-结合软决策树的分层强化学习算法（HEE）中的上层决策模型" class="headerlink" title="4.2 结合软决策树的分层强化学习算法（HEE）中的上层决策模型"></a>4.2 结合软决策树的分层强化学习算法（HEE）中的上层决策模型</h3><ul><li><strong>软决策树（SDT）</strong>：引入软决策树结构，改进传统的决策树模型，使其可以替代神经网络拟合动作价值函数，增强模型的可解释性。</li><li><strong>线性权重</strong>：在软决策树的叶子节点引入线性模型，通过线性权重表示状态特征与决策结果之间的因果逻辑，增强策略的解释性。</li></ul><h3 id="4-3-基于模糊决策树的博弈对抗策略中的上层决策模型"><a href="#4-3-基于模糊决策树的博弈对抗策略中的上层决策模型" class="headerlink" title="4.3 基于模糊决策树的博弈对抗策略中的上层决策模型"></a>4.3 基于模糊决策树的博弈对抗策略中的上层决策模型</h3><ul><li><strong>模糊决策树</strong>：构建模糊决策树模拟人的决策过程，处理高维度数据集中的模糊性和不确定性，提高分类的准确率和模型的泛化能力。</li><li><strong>战法规则提取</strong>：从模糊决策树中提取隐含的战法规则，建立以IF-THEN规则形式表示的博弈对抗策略。</li></ul><h3 id="4-4-实现细节"><a href="#4-4-实现细节" class="headerlink" title="4.4 实现细节"></a>4.4 实现细节</h3><ul><li><strong>神经网络建模</strong>：上层决策模型通常采用神经网络进行建模，使用深度学习技术来处理高维数据和复杂的决策问题。</li><li><strong>参数更新</strong>：上层决策模型的参数通过梯度下降法进行更新，利用经验回放机制和策略梯度方法来优化模型性能。</li><li><strong>目标分解</strong>：上层智能体学习目标的分解策略，将复杂的任务分解为多个子目标，通过子目标的实现逐步达成最终目标。</li></ul><h3 id="4-5-应用场景"><a href="#4-5-应用场景" class="headerlink" title="4.5 应用场景"></a>4.5 应用场景</h3><ul><li><strong>联合作战实验平台</strong>：在空战博弈场景和海空联合作战场景中，上层决策模型负责制定整体作战策略，指导下层作战单元执行具体的作战任务。</li></ul><h2 id="5-上层决策模型的具体实现细节"><a href="#5-上层决策模型的具体实现细节" class="headerlink" title="5. 上层决策模型的具体实现细节"></a>5. 上层决策模型的具体实现细节</h2><h3 id="5-1-指挥官-集群分层强化学习算法（HES）的上层决策模型"><a href="#5-1-指挥官-集群分层强化学习算法（HES）的上层决策模型" class="headerlink" title="5.1 指挥官-集群分层强化学习算法（HES）的上层决策模型"></a>5.1 指挥官-集群分层强化学习算法（HES）的上层决策模型</h3><h4 id="设计理念"><a href="#设计理念" class="headerlink" title="设计理念"></a>设计理念</h4><ul><li><strong>指挥官角色</strong>：模拟高级指挥官的决策过程，负责在战争或博弈的宏观层面上制定战略。</li><li><strong>任务分解</strong>：将复杂的任务分解为可解释的子任务，这些子任务对下层集群作战模型来说是具体的战术目标。</li></ul><h4 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h4><ul><li><strong>神经网络架构</strong>：使用神经网络来拟合指挥官的决策策略，该网络输入全局观测状态，输出子任务或战术目标。</li><li><strong>模仿学习</strong>：基于专家经验设计可解释的子任务，通过模仿学习将专家知识整合到神经网络的训练过程中。</li><li><strong>参数更新</strong>：利用梯度下降方法更新神经网络参数，以最小化损失函数，提高决策质量。</li></ul><h3 id="5-2-结合软决策树的分层强化学习算法（HEE）的上层决策模型"><a href="#5-2-结合软决策树的分层强化学习算法（HEE）的上层决策模型" class="headerlink" title="5.2 结合软决策树的分层强化学习算法（HEE）的上层决策模型"></a>5.2 结合软决策树的分层强化学习算法（HEE）的上层决策模型</h3><h4 id="设计理念-1"><a href="#设计理念-1" class="headerlink" title="设计理念"></a>设计理念</h4><ul><li><strong>软决策树（SDT）</strong>：引入软决策树来增强策略的解释性，SDT 结合了神经网络的非线性建模能力和决策树的可解释性。</li></ul><h4 id="实现细节-1"><a href="#实现细节-1" class="headerlink" title="实现细节"></a>实现细节</h4><ul><li><strong>树结构优化</strong>：对传统的软决策树结构进行改进，引入线性权重来表示状态特征与决策结果之间的因果逻辑。</li><li><strong>线性叶子节点</strong>：在SDT的叶子节点使用线性模型，这些模型通过学习状态特征的权重来预测动作价值。</li><li><strong>在线学习</strong>：SDT模型支持在线学习，能够根据实时数据更新模型参数，增强模型对新态势的适应能力。</li></ul><h3 id="5-3-基于模糊决策树的博弈对抗策略的上层决策模型"><a href="#5-3-基于模糊决策树的博弈对抗策略的上层决策模型" class="headerlink" title="5.3 基于模糊决策树的博弈对抗策略的上层决策模型"></a>5.3 基于模糊决策树的博弈对抗策略的上层决策模型</h3><h4 id="设计理念-2"><a href="#设计理念-2" class="headerlink" title="设计理念"></a>设计理念</h4><ul><li><strong>模糊决策树</strong>：利用模糊决策树处理高维度数据集中的模糊性和不确定性，提高决策的准确性和泛化能力。</li></ul><h4 id="实现细节-2"><a href="#实现细节-2" class="headerlink" title="实现细节"></a>实现细节</h4><ul><li><strong>属性模糊化</strong>：将连续型属性转换为模糊集合，并通过隶属度函数计算属性值在模糊集合中的隶属度。</li><li><strong>分裂属性选择</strong>：基于分类不确定性选择分裂属性，以最小化节点的平均模糊信息熵。</li><li><strong>战法规则提取</strong>：从模糊决策树中提取IF-THEN形式的战法规则，为博弈对抗提供具体的策略指导。</li></ul><h3 id="5-4-通用实现细节"><a href="#5-4-通用实现细节" class="headerlink" title="5.4 通用实现细节"></a>5.4 通用实现细节</h3><h4 id="损失函数与优化"><a href="#损失函数与优化" class="headerlink" title="损失函数与优化"></a>损失函数与优化</h4><ul><li><strong>损失函数</strong>：设计损失函数以衡量模型预测与实际结果之间的差异，常用的损失函数包括均方误差等。</li><li><strong>优化算法</strong>：采用Adam优化器等高级优化算法来更新模型参数，提高训练效率和模型性能。</li></ul><h4 id="训练与验证"><a href="#训练与验证" class="headerlink" title="训练与验证"></a>训练与验证</h4><ul><li><strong>训练过程</strong>：通过与环境的交互不断收集数据，利用这些数据训练上层决策模型。</li><li><strong>验证与测试</strong>：在不同的博弈场景中验证上层决策模型的有效性，调整模型参数以适应不同的战术需求。</li></ul><p>这些实现细节共同构成了上层决策模型的核心，使其能够在多智能体博弈对抗中发挥关键作用。通过这些细节的实现，上层决策模型能够提供有效的战略指导，并与下层执行模型协同工作，实现整体任务目标。</p><p>[1]乔天润.基于分层强化学习的多智能体博弈对抗策略[D].东南大学,2023.DOI:10.27014&#x2F;d.cnki.gdnau.2023.001144.</p>]]></content>
    
    
    <categories>
      
      <category>科研</category>
      
      <category>多智能体强化学习任务分配</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RL</tag>
      
      <tag>科研</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于多智能体强化学习的分层决策优化方法</title>
    <link href="/2024/11/15/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1%E5%88%86%E9%85%8D/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%88%86%E5%B1%82%E5%86%B3%E7%AD%96%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/"/>
    <url>/2024/11/15/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1%E5%88%86%E9%85%8D/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%88%86%E5%B1%82%E5%86%B3%E7%AD%96%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="1-主要内容"><a href="#1-主要内容" class="headerlink" title="1. 主要内容"></a>1. 主要内容</h1><ol><li><strong>背景与目的</strong>：<ul><li>随着信息技术和人工智能的发展，大数据驱动的辅助决策方法变得更加科学和准确。</li><li>强化学习在决策优化方面具有优势，但传统方法难以解决多层次、多目标的决策优化问题，尤其是在长周期决策优化问题中，学习奖励的滞后性限制了效率。</li></ul></li><li><strong>方法论</strong>：<ul><li>提出基于多智能体强化学习的分层决策优化方法，应用目标分解思想解决长期决策优化问题。</li><li>该方法基于强化学习理论，使具有层级关系的多智能体相互合作，上层智能体学习目标的分解策略，下层智能体学习完成目标的行动策略。</li></ul></li></ol><h1 id="2-研究方法"><a href="#2-研究方法" class="headerlink" title="2. 研究方法"></a>2. 研究方法</h1><p>文章中提到的分层决策优化方法（HDQ）算法的具体实现涉及以下几个关键步骤：</p><ol><li><p><strong>定义智能体和环境交互</strong>：</p><ul><li>强化学习基于马尔可夫决策过程（MDP），包含状态集合 ( S )，动作集合 ( A )，状态转移矩阵 ( P )，奖励集合 ( R )，以及折扣率 ( \gamma )。</li></ul></li><li><p><strong>目标分解与层级决策</strong>：</p><ul><li>将长期目标 ( G ) 分解为子目标 ( g_t )，并通过计算状态 ( s_t ) 与子目标 ( g_t ) 之间的距离 ( dis(gt, st) ) 来判断子目标是否完成。</li></ul></li><li><p><strong>智能体的层级结构</strong>：</p><ul><li>设计具有层级关系的上层智能体 ( \pi_1 ) 和下层智能体 ( \pi_2 )。</li><li>上层智能体学习目标的分解策略，下层智能体学习实现子目标的行动策略。</li></ul></li><li><p><strong>神经网络建模</strong>：</p><ul><li>使用深度Q网络（DQN）作为值函数逼近器，引入神经网络来估计动作价值 ( Q(s, a; \theta) )。</li><li>采用Dueling DQN来缓解高估Q值的问题，引入优势函数 ( A(s, a) )。</li></ul></li><li><p><strong>智能体的参数更新</strong>：</p><ul><li>智能体参数交替更新，共同学习完成团队任务的最佳策略。</li><li>使用梯度下降法更新神经网络参数 ( \theta )，学习率 ( \alpha )。</li></ul></li><li><p><strong>实验设计与数据预处理</strong>：</p><ul><li>从MIMIC-IV数据库中提取脓毒症患者数据，包括性别、年龄、体重、SOFA评分等45个特征。</li><li>使用均值插值方法处理缺失值，最大最小归一化方法消除特征量纲。</li></ul></li><li><p><strong>状态和动作空间的定义</strong>：</p><ul><li>状态空间通过K-means算法聚类降维，定义700个不同的状态类别。</li><li>子目标基于SOFA评分，动作空间定义为两种药物组成的二维矩阵。</li></ul></li><li><p><strong>奖励函数的设计</strong>：</p><ul><li>设计分段常数函数作为奖励函数，根据患者的生存状态和状态改善情况给予不同的奖励。</li></ul></li></ol><p>[1]张倩,李天皓,白春光.基于多智能体强化学习的分层决策优化方法[J].电子科技大学学报(社科版),2022,24(06):90-96.DOI:10.14071&#x2F;j.1008-8105(2022)-1056.</p>]]></content>
    
    
    <categories>
      
      <category>科研</category>
      
      <category>多智能体强化学习任务分配</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RL</tag>
      
      <tag>科研</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于层次控制的多智能体对抗研究</title>
    <link href="/2024/11/14/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1%E5%88%86%E9%85%8D/%E5%9F%BA%E4%BA%8E%E5%B1%82%E6%AC%A1%E6%8E%A7%E5%88%B6%E7%9A%84%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%AF%B9%E6%8A%97%E7%A0%94%E7%A9%B6/"/>
    <url>/2024/11/14/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1%E5%88%86%E9%85%8D/%E5%9F%BA%E4%BA%8E%E5%B1%82%E6%AC%A1%E6%8E%A7%E5%88%B6%E7%9A%84%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%AF%B9%E6%8A%97%E7%A0%94%E7%A9%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="1-主要内容"><a href="#1-主要内容" class="headerlink" title="1. 主要内容"></a>1. 主要内容</h1><ul><li>针对复杂动作状态空间场景下单智能体策略学习问题，提出了一种基于预训练模型的分层强化学习算法。该算法分为三个层次：<ul><li>首先，基于先验知识为每个子策略设计了适宜其相应时间的宏动作；</li><li>其次是子策略控制器，其核心是基于监督学习的方法，训练能够适应不同需要的子策略，基于随机的宏动作产生子策略监督学习的数据，并且子策略只学习胜利时的操作轨迹；</li><li>最后是智能体的高级策略控制器，基于策略梯度算法进行扩展，屏蔽了底层繁琐的动作，只对于下层的子策略进行选择，使得作为决策的神经网络参数能够做出更好的动作。</li></ul></li><li>针对复杂动作状态空间场景下多智能体策略学习问题，提出了一种基于双向协调网络的多智能体强化学习算法。该算法基于Actor-Critic框架，其特点是：<ul><li>基于全局信息训练Critic网络，用以解决场景中马尔可夫性缺失问题；</li><li>采用双向RNN网络结构，用以解决场景中多智能体信息通信问题；</li><li>使用动作映射算法，使得智能体选择收益最高的合法联合动作。</li></ul></li><li>基于上述研究成果和《星际争霸2》对抗学习环境，将单智能体强化学习算法和多智能体强化学习算法进行有机融合，设计实现了一个基于层次控制的多智能体强化学习原型系统，并进行实验验证。</li></ul><h1 id="2-研究方法"><a href="#2-研究方法" class="headerlink" title="2. 研究方法"></a>2. 研究方法</h1><p>这篇论文的主要研究方法和算法集中在解决复杂动作状态空间下的多智能体对抗问题，具体包括以下几个方面：</p><ol><li><p><strong>基于预训练模型的分层强化学习算法</strong>：</p><ul><li><strong>宏动作设计</strong>：将复杂的动作序列打包成宏动作，减少智能体需要学习的原子动作数量。</li><li><strong>子策略控制器</strong>：基于监督学习的方法训练子策略，每个子策略对应一个宏动作。</li><li><strong>高级策略控制器（APC）</strong>：基于策略梯度算法扩展，负责在子策略之间进行选择。</li></ul></li><li><p><strong>基于双向协调网络的多智能体强化学习算法（BiC-DDPG）</strong>：</p><ul><li><strong>集中训练分散执行</strong>：解决多智能体对抗场景下马尔可夫性缺失问题，提高算法收敛性。</li><li><strong>Bi-RNN网络结构</strong>：实现智能体合作时的信息通信。</li><li><strong>动作映射算法</strong>：将连续的原始联合动作映射到合法离散联合动作空间，解决复杂联合动作空间下的智能体决策问题。</li></ul></li><li><p><strong>深度学习和强化学习算法</strong>：</p><ul><li><strong>深度神经网络</strong>：使用深度神经网络结构（如ResNet50）作为子策略的神经网络结构。</li><li><strong>强化学习算法</strong>：包括Q学习、DQN、策略梯度、Actor-Critic算法等。</li></ul></li><li><p><strong>实验验证</strong>：</p><ul><li>在《星际争霸2》环境中进行实验验证，包括全流程对抗和微操作对抗环境。</li><li>设计了不同难度的对抗场景，以及不同的子策略训练和测试。</li></ul></li><li><p><strong>原型系统实现</strong>：</p><ul><li>将单智能体和多智能体强化学习算法融合，设计实现了一个基于层次控制的多智能体强化学习原型系统。</li><li>在Python-sc2接口上复现SMAC接口对于观察数据、奖励机制以及动作空间的设计，并部署BiC-DDPG算法。</li></ul></li><li><p><strong>算法优化和调整</strong>：</p><ul><li>对算法的参数进行调整，以适应不同的实验环境和场景。</li><li>通过实验结果分析算法的性能和有效性。</li></ul></li></ol><p>[1]王功举.基于层次控制的多智能体对抗研究[D].军事科学院,2021.DOI:10.27193&#x2F;d.cnki.gjsky.2021.000110.</p>]]></content>
    
    
    <categories>
      
      <category>科研</category>
      
      <category>多智能体强化学习任务分配</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RL</tag>
      
      <tag>科研</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>3.3 无监督学习-强化学习-吴恩达</title>
    <link href="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/"/>
    <url>/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/</url>
    
    <content type="html"><![CDATA[<h2 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h2><p><img src="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013185527334.png"></p><p><img src="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013185513926.png"></p><ul><li>状态、动作、奖励和下一个状态(s, a, R(s), s’)</li></ul><h3 id="1-回报"><a href="#1-回报" class="headerlink" title="1. 回报"></a>1. 回报</h3><ul><li>折扣因子</li></ul><p><img src="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013191147456.png"></p><p><img src="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013191515723.png"></p><h3 id="2-决策"><a href="#2-决策" class="headerlink" title="2. 决策"></a>2. 决策</h3><p><img src="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013191936751.png"></p><p><img src="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013192130503.png"></p><ul><li><p>马尔可夫决策过程 MDP</p></li><li><p>在马尔可夫决策过程中，未来只取决于你现在所处的位置，而不取决于你是如何到达这里的。</p></li></ul><h3 id="3-状态-动作价值函数"><a href="#3-状态-动作价值函数" class="headerlink" title="3. 状态-动作价值函数"></a>3. 状态-动作价值函数</h3><p><img src="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013214059896.png"></p><p><img src="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013214515098.png"></p><h4 id="3-1-贝尔曼方程"><a href="#3-1-贝尔曼方程" class="headerlink" title="3.1 贝尔曼方程"></a>3.1 贝尔曼方程</h4><p><img src="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013220256063.png"></p><p><img src="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013221245911.png"></p><ul><li>如果你从状态s 开始，你将采取行动a，然后在此之后采取最佳行动，那么你将随着时间的推移看到一些奖励序列。</li></ul><p><img src="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013221652384.png"></p><p><img src="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013221916868.png"></p><h3 id="4-随机强化学习"><a href="#4-随机强化学习" class="headerlink" title="4. 随机强化学习"></a>4. 随机强化学习</h3><p><img src="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013222607911.png"></p><h3 id="5-连续状态"><a href="#5-连续状态" class="headerlink" title="5. 连续状态"></a>5. 连续状态</h3><p><img src="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013222846102.png"></p><ul><li>连续马尔可夫 MTP</li></ul><h3 id="6-学习状态值函数"><a href="#6-学习状态值函数" class="headerlink" title="6. 学习状态值函数"></a>6. 学习状态值函数</h3><p><img src="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013223922575.png"></p><p><img src="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013224639866.png"></p><ul><li>不知道Q，随机猜测</li></ul><h3 id="7-DQN"><a href="#7-DQN" class="headerlink" title="7. DQN"></a>7. DQN</h3><ul><li>意思是神经网络里的参数随机初始化，然后(s’,a’)输入，得到maxQ的预测</li></ul><p><img src="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013225256166.png"></p><ul><li>交给神经网络训练的参数y中一部分是随机初始化神经网络生成的，但还有一部分是包含了当前状态的信息的，所以当训练次数增多后，外部的输入信息会逐步冲刷掉初始化的随机信息，给出真正的Q函数估计。</li></ul><p><img src="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013225733542.png"></p><h4 id="7-1-贪婪算法"><a href="#7-1-贪婪算法" class="headerlink" title="7.1 贪婪算法"></a>7.1 贪婪算法</h4><ul><li>使用高ε开始，逐步降低直到0.01</li></ul><p><img src="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013230506858.png"></p><h4 id="7-2-小批量和软更新"><a href="#7-2-小批量和软更新" class="headerlink" title="7.2 小批量和软更新"></a>7.2 小批量和软更新</h4><p><img src="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013230853479.png"></p><p><img src="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013231149426.png"></p><p><img src="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013231255361.png"></p><p><img src="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013231653864.png"></p><h3 id="8-局限性"><a href="#8-局限性" class="headerlink" title="8. 局限性"></a>8. 局限性</h3><p><img src="/2024/11/14/ML/class3-week3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013232030585.png"></p>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
      <category>ML</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ML</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>3.2 无监督学习-推荐系统-吴恩达</title>
    <link href="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/"/>
    <url>/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/</url>
    
    <content type="html"><![CDATA[<h2 id="推荐系统"><a href="#推荐系统" class="headerlink" title="推荐系统"></a>推荐系统</h2><h3 id="1-使用每个特征数据"><a href="#1-使用每个特征数据" class="headerlink" title="1. 使用每个特征数据"></a>1. 使用每个特征数据</h3><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013091417801.png"></p><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013092525171.png"></p><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013092709205.png"></p><h3 id="2-协同过滤算法"><a href="#2-协同过滤算法" class="headerlink" title="2. 协同过滤算法"></a>2. 协同过滤算法</h3><ul><li>假设已经有了w和b，猜测特征x</li></ul><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013093541589.png"></p><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013094256436.png"></p><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013094536963.png"></p><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013095022269.png"></p><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013095116749.png"></p><ul><li><p>这种协同过滤是从多个用户收集数据，用户之间的这种协作可帮助您预测未来甚至其他用户的评级。</p></li><li><p>推荐系统的一个非常常见的用例是当您有二进制标签时，例如用户喜欢、喜欢或与项目交互的标签。</p></li></ul><h3 id="3-二进制标签"><a href="#3-二进制标签" class="headerlink" title="3.二进制标签"></a>3.二进制标签</h3><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013095506383.png"></p><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013095650568.png"></p><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013095901608.png"></p><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013100113430.png"></p><ul><li>分类不用正则化</li></ul><h3 id="4-均值归一化"><a href="#4-均值归一化" class="headerlink" title="4. 均值归一化"></a>4. 均值归一化</h3><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013143727458.png"></p><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013144130791.png"></p><ul><li>对未知用户，预测评分为均值</li></ul><h3 id="5-协同过滤Tensorflow实现"><a href="#5-协同过滤Tensorflow实现" class="headerlink" title="5. 协同过滤Tensorflow实现"></a>5. 协同过滤Tensorflow实现</h3><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013144725579.png"></p><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013144803015.png"></p><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013145539351.png"></p><h3 id="6-寻找相关特征"><a href="#6-寻找相关特征" class="headerlink" title="6. 寻找相关特征"></a>6. 寻找相关特征</h3><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013145951931.png"></p><ul><li>协同过滤的局限性</li></ul><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013150021292.png"></p><ul><li><p>冷启动问题</p></li><li><p>边缘信息</p></li></ul><h3 id="7-基于内容的过滤算法"><a href="#7-基于内容的过滤算法" class="headerlink" title="7. 基于内容的过滤算法"></a>7. 基于内容的过滤算法</h3><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013150639264.png"></p><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013150936617.png"></p><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013151110932.png"></p><ul><li>如何计算V</li></ul><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013151407807.png"></p><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013151905392.png"></p><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013152534237.png"></p><h3 id="8-从大型目录中推荐"><a href="#8-从大型目录中推荐" class="headerlink" title="8. 从大型目录中推荐"></a>8. 从大型目录中推荐</h3><ul><li>两个步骤：检索和排名</li></ul><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013152823434.png"></p><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013153036731.png"></p><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013153343967.png"></p><h3 id="9-基于内容的Tensorflow实现"><a href="#9-基于内容的Tensorflow实现" class="headerlink" title="9. 基于内容的Tensorflow实现"></a>9. 基于内容的Tensorflow实现</h3><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013154612258.png"></p><h3 id="10-降低特征数量"><a href="#10-降低特征数量" class="headerlink" title="10. 降低特征数量"></a>10. 降低特征数量</h3><ul><li>PCA主成分分析法，特征降为二维或者三维，便于可视化</li></ul><h4 id="10-1-PCA算法"><a href="#10-1-PCA算法" class="headerlink" title="10.1 PCA算法"></a>10.1 PCA算法</h4><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013170727751.png"></p><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013171217861.png"></p><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013171447596.png"></p><ul><li><p>当使用线性回归来预测目标输出Y并且PCA试图获取大量特征并平等对待它们并减少很好地表示数据所需的轴数</p></li><li><p>因此，如果您尝试预测y的值，则应使用线性回归;如果您尝试减少数据集中的特征数量，例如将其可视化，则应使用PCA。</p></li></ul><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013172253829.png"></p><ul><li>每个特征的方差贡献率</li></ul><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013172530272.png"></p><p><img src="/2024/11/14/ML/class3-week2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013172923497.png"></p>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
      <category>ML</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ML</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>3.1 无监督学习-无监督学习-吴恩达</title>
    <link href="/2024/11/14/ML/class3-week1-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/"/>
    <url>/2024/11/14/ML/class3-week1-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/</url>
    
    <content type="html"><![CDATA[<h2 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h2><h3 id="1-聚类"><a href="#1-聚类" class="headerlink" title="1. 聚类"></a>1. 聚类</h3><h4 id="1-1-k-means"><a href="#1-1-k-means" class="headerlink" title="1.1 k-means"></a>1.1 k-means</h4><p><img src="/2024/11/14/ML/class3-week1-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012125528206.png"></p><p><img src="/2024/11/14/ML/class3-week1-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012125536447.png"></p><p><img src="/2024/11/14/ML/class3-week1-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012130426099.png"></p><ul><li>如果一个集群训练样本为零，可以消除该集群，最终得到k-1；另一种方法是重新初始化该集群质心</li></ul><h4 id="1-2-优化目标"><a href="#1-2-优化目标" class="headerlink" title="1.2 优化目标"></a>1.2 优化目标</h4><p><img src="/2024/11/14/ML/class3-week1-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012145049473.png"></p><h4 id="1-3-初始化"><a href="#1-3-初始化" class="headerlink" title="1.3 初始化"></a>1.3 初始化</h4><p><img src="/2024/11/14/ML/class3-week1-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012150757199.png"></p><p><img src="/2024/11/14/ML/class3-week1-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012151542672.png"></p><h4 id="1-4-选择聚类数量"><a href="#1-4-选择聚类数量" class="headerlink" title="1.4 选择聚类数量"></a>1.4 选择聚类数量</h4><ul><li>肘法</li></ul><p><img src="/2024/11/14/ML/class3-week1-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012151925053.png"></p><p><img src="/2024/11/14/ML/class3-week1-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012152146445.png"></p><h3 id="2-异常检测"><a href="#2-异常检测" class="headerlink" title="2. 异常检测"></a>2. 异常检测</h3><p><img src="/2024/11/14/ML/class3-week1-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012152706177.png"></p><h4 id="2-1-密度估计"><a href="#2-1-密度估计" class="headerlink" title="2.1 密度估计"></a>2.1 密度估计</h4><p><img src="/2024/11/14/ML/class3-week1-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012152845235.png"></p><p><img src="/2024/11/14/ML/class3-week1-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012153346742.png"></p><h4 id="2-2-高斯正态分布"><a href="#2-2-高斯正态分布" class="headerlink" title="2.2 高斯正态分布"></a>2.2 高斯正态分布</h4><ul><li>最大似然估计</li></ul><h4 id="2-3-异常检测算法"><a href="#2-3-异常检测算法" class="headerlink" title="2.3 异常检测算法"></a>2.3 异常检测算法</h4><p><img src="/2024/11/14/ML/class3-week1-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012154133115.png"></p><p><img src="/2024/11/14/ML/class3-week1-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012154923207.png"></p><h4 id="2-4-开发与评估异常检测系统"><a href="#2-4-开发与评估异常检测系统" class="headerlink" title="2.4 开发与评估异常检测系统."></a>2.4 开发与评估异常检测系统.</h4><p><img src="/2024/11/14/ML/class3-week1-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012215712447.png"></p><p><img src="/2024/11/14/ML/class3-week1-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012220215931.png"></p><ul><li><p>这种替代方案的缺点是，在调整算法后，您没有公平的方法来判断它在未来示例中的实际效果如何，因为您没有测试集。</p></li><li><p>当你的数据集很小的时候，特别是当你有异常的数量时，你的数据集很小，这可能是你最好的选择。</p></li></ul><p><img src="/2024/11/14/ML/class3-week1-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013082659472.png"></p><h4 id="2-5-异常检测vs监督学习"><a href="#2-5-异常检测vs监督学习" class="headerlink" title="2.5 异常检测vs监督学习"></a>2.5 异常检测vs监督学习</h4><p><img src="/2024/11/14/ML/class3-week1-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013084827450.png"></p><ul><li>例子</li></ul><p><img src="/2024/11/14/ML/class3-week1-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013084924028.png"></p><h4 id="2-6-选择用什么特征"><a href="#2-6-选择用什么特征" class="headerlink" title="2.6 选择用什么特征"></a>2.6 选择用什么特征</h4><ul><li>特征改变为高斯分布</li></ul><p><img src="/2024/11/14/ML/class3-week1-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013085546244.png"></p><p><img src="/2024/11/14/ML/class3-week1-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013090207839.png"></p><p><img src="/2024/11/14/ML/class3-week1-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231013090413780.png"></p>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
      <category>ML</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ML</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2.4 深度学习-决策树-吴恩达</title>
    <link href="/2024/11/14/ML/class2-week4-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-%E5%90%B4%E6%81%A9%E8%BE%BE/"/>
    <url>/2024/11/14/ML/class2-week4-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-%E5%90%B4%E6%81%A9%E8%BE%BE/</url>
    
    <content type="html"><![CDATA[<h2 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h2><p><img src="/2024/11/14/ML/class2-week4-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012075401986.png"></p><p><img src="/2024/11/14/ML/class2-week4-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012075410387.png"></p><ul><li><p>根节点 决策节点 叶节点</p></li><li><p>决策树学习算法的工作是，从所有可能的决策树中，尝试选择一个希望在训练集上表现良好的树，然后理想地泛化到新数据，例如交叉验证和测试集</p></li></ul><h3 id="1-学习过程"><a href="#1-学习过程" class="headerlink" title="1. 学习过程"></a>1. 学习过程</h3><ul><li>决策树学习的第一步是，我们必须决定在根节点使用什么特征。</li></ul><p><img src="/2024/11/14/ML/class2-week4-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012081611286.png"></p><ul><li><p>决策 2：何时停止分裂？</p><ul><li>当一个节点完全是一类时</li><li>当分裂一个节点会导致树超过最大深度时</li><li>当纯度分数的提高低于一个阈值时</li><li>当节点中的样本数量低于一个阈值时</li></ul></li><li><p>您可能想要限制决策树深度的一个原因是确保我们的树不会变得太大和笨重，其次，通过保持树小，它不太容易过度拟合。</p></li></ul><h3 id="2-纯度"><a href="#2-纯度" class="headerlink" title="2. 纯度"></a>2. 纯度</h3><h4 id="2-1-熵-entropy"><a href="#2-1-熵-entropy" class="headerlink" title="2.1 熵 entropy"></a>2.1 熵 entropy</h4><p><img src="/2024/11/14/ML/class2-week4-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012082638836.png"></p><p><img src="/2024/11/14/ML/class2-week4-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012082823450.png"></p><ul><li><p>选择拆分信息增益</p></li><li><p>减少熵</p></li><li><p>信息增益 分之前的熵减去分后熵的加权平均</p></li><li><p>停止标准，每次信息增益如果太小停止分类</p></li></ul><p><img src="/2024/11/14/ML/class2-week4-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012083632353.png"></p><p><img src="/2024/11/14/ML/class2-week4-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012083921344.png"></p><h4 id="2-2-整合"><a href="#2-2-整合" class="headerlink" title="2.2 整合"></a>2.2 整合</h4><ul><li>从根节点开始，包含所有样本</li><li>计算所有可能特征的信息增益，并选择信息增益最高的特征</li><li>根据选定的特征划分数据集，并创建树的左分支和右分支</li><li>持续重复分裂过程，直到满足停止条件：<ul><li>当一个节点完全是一类时</li><li>当分裂一个节点会导致树超过最大深度时</li><li>额外分裂的信息增益小于阈值时</li><li>当节点中的样本数量低于阈值时</li></ul></li></ul><p><img src="/2024/11/14/ML/class2-week4-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012084601880.png"></p><ul><li>递归分类</li></ul><h3 id="3-独热编码-one-hot"><a href="#3-独热编码-one-hot" class="headerlink" title="3. 独热编码 one-hot"></a>3. 独热编码 one-hot</h3><p><img src="/2024/11/14/ML/class2-week4-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012085239987.png"></p><ul><li><p>通过one-hot编码，您可以让决策树处理可以采用两个以上离散值的特征，您还可以将其应用于新网络或线性回归或逻辑回归训练。</p></li><li><p>连续值</p></li><li><p>尝试不同的阈值，计算纯度</p></li></ul><h3 id="4-回归树"><a href="#4-回归树" class="headerlink" title="4. 回归树"></a>4. 回归树</h3><p><img src="/2024/11/14/ML/class2-week4-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012090404205.png"></p><ul><li>尝试减少方差</li></ul><p><img src="/2024/11/14/ML/class2-week4-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012091154958.png"></p><h3 id="5-使用多个决策树"><a href="#5-使用多个决策树" class="headerlink" title="5. 使用多个决策树"></a>5. 使用多个决策树</h3><p><img src="/2024/11/14/ML/class2-week4-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012092643280.png"></p><h4 id="5-1-有放回的采样"><a href="#5-1-有放回的采样" class="headerlink" title="5.1 有放回的采样"></a>5.1 有放回的采样</h4><ul><li><p>构建新的数据集</p></li><li><p>随机森林算法 Random Forest Algorithm</p></li></ul><p><img src="/2024/11/14/ML/class2-week4-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012093230276.png"></p><ul><li><p>随机化特征选择</p><ul><li>在每个节点选择用于分裂的特征时，如果有n个特征可用，随机选择一个包含k个特征的子集（k &lt; n），并允许算法仅从这个特征子集中进行选择。</li></ul></li><li><p>k的选择（根号n，log2(n)）</p></li></ul><h4 id="5-2-XGBoost-extreme-Gradient-Boosting"><a href="#5-2-XGBoost-extreme-Gradient-Boosting" class="headerlink" title="5.2 XGBoost (extreme Gradient Boosting)"></a>5.2 XGBoost (extreme Gradient Boosting)</h4><ul><li>提升树的开源实现</li><li>快速高效的实现</li><li>默认分裂标准和停止分裂标准的好选择</li><li>内置正则化以防止过拟合</li><li>机器学习竞赛中极具竞争力的算法（例如：Kaggle竞赛）</li></ul><p><img src="/2024/11/14/ML/class2-week4-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012094738491.png"></p><h3 id="6-何时使用决策树"><a href="#6-何时使用决策树" class="headerlink" title="6. 何时使用决策树"></a>6. 何时使用决策树</h3><ul><li>表格数据</li></ul><p><img src="/2024/11/14/ML/class2-week4-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012095356821.png"></p><p><img src="/2024/11/14/ML/class2-week4-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231012095814528.png"></p>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
      <category>ML</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ML</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2.3 深度学习-在机器学习项目中下一步该做什么-吴恩达</title>
    <link href="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/"/>
    <url>/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/</url>
    
    <content type="html"><![CDATA[<h2 id="在机器学习项目中下一步该做什么"><a href="#在机器学习项目中下一步该做什么" class="headerlink" title="在机器学习项目中下一步该做什么"></a>在机器学习项目中下一步该做什么</h2><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011083027133.png"></p><h3 id="1-模型评估"><a href="#1-模型评估" class="headerlink" title="1. 模型评估"></a>1. 模型评估</h3><p>训练集分为两个子集</p><ul><li><p>training set</p></li><li><p>test set</p></li></ul><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011083802084.png"></p><p>不包含正则化项</p><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011084012544.png"></p><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011084442975.png" alt="image-20231011084442975"></p><p>就是相比于之前计算在测试集和训练集上误差的那两个公式，我们更常用模型分类错误的次数除以总的预测次数来表示误差</p><p>就是对于逻辑回归来说，可以通过计算误判占比的方法来代表成本函数，比如test set中误判的占比是10％，那么J test就是0.1</p><h4 id="1-1-分为三个子集，训练集、交叉验证集、测试集"><a href="#1-1-分为三个子集，训练集、交叉验证集、测试集" class="headerlink" title="1.1 分为三个子集，训练集、交叉验证集、测试集"></a>1.1 分为三个子集，训练集、交叉验证集、测试集</h4><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011091646019.png"></p><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011091757791.png"></p><ul><li><p>选择最小的交叉验证集误差对应的模型</p></li><li><p>用测试集来评估泛化误差</p></li></ul><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011092256493.png"></p><h4 id="1-2-偏差和方差"><a href="#1-2-偏差和方差" class="headerlink" title="1.2 偏差和方差"></a>1.2 偏差和方差</h4><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011093159868.png"></p><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011093401564.png"></p><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011093433520.png"></p><ul><li>正则化如何影响偏差和方差，从而影响算法的性能</li></ul><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011093859951.png"></p><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011094124259.png"></p><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011094256539.png"></p><h4 id="1-3-指定一个用于性能评估的基准"><a href="#1-3-指定一个用于性能评估的基准" class="headerlink" title="1.3 指定一个用于性能评估的基准"></a>1.3 指定一个用于性能评估的基准</h4><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011103735186.png"></p><p>竞争算法</p><h4 id="1-4-学习曲线"><a href="#1-4-学习曲线" class="headerlink" title="1.4 学习曲线"></a>1.4 学习曲线</h4><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011104512509.png"></p><ul><li>训练集变大，误差增大</li></ul><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011104852894.png"></p><ul><li>这给出了这个结论，也许有点令人惊讶，如果学习算法具有高偏差，获得更多的训练数据本身就没有那么大的希望。</li></ul><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011105426342.png"></p><ul><li>所以在这种情况下，可能仅仅通过增加训练集的大小来降低交叉验证误差并让你的算法表现得越来越好，这与高偏差情况不同，在这种情况下你唯一要做的就是获得更多的训练数据，实际上并不能帮助您了解算法性能。</li></ul><h4 id="1-5-如何改进"><a href="#1-5-如何改进" class="headerlink" title="1.5 如何改进"></a>1.5 如何改进</h4><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011110222504.png"></p><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011110708303.png"></p><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011111707005.png"></p><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011112028987.png"></p><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011112250065.png"></p><h3 id="2-机器学习开发的迭代"><a href="#2-机器学习开发的迭代" class="headerlink" title="2. 机器学习开发的迭代"></a>2. 机器学习开发的迭代</h3><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011112605831.png"></p><ul><li>垃圾邮件分类</li></ul><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011112929003.png"></p><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011113910756.png"></p><h4 id="2-1-误差分析"><a href="#2-1-误差分析" class="headerlink" title="2.1 误差分析"></a>2.1 误差分析</h4><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011114442995.png"></p><h4 id="2-2-数据增强"><a href="#2-2-数据增强" class="headerlink" title="2.2 数据增强"></a>2.2 数据增强</h4><ul><li>旋转图像扭曲放大缩小</li></ul><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011115040740.png"></p><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011115116926.png"></p><ul><li>音频增强</li></ul><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011115211067.png"></p><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011115324412.png"></p><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011131113956.png"></p><h4 id="2-3-迁移学习-Transfer-learning"><a href="#2-3-迁移学习-Transfer-learning" class="headerlink" title="2.3 迁移学习 Transfer  learning"></a>2.3 迁移学习 Transfer  learning</h4><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011163140324.png"></p><ul><li><p>数据集小选择1，数据集大选择2</p></li><li><p>先在大的数据集训练（监督与训练），再在小的训练称为微调</p></li></ul><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011163230072.png"></p><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011163351440.png"></p><h4 id="2-4-机器学习项目全周期"><a href="#2-4-机器学习项目全周期" class="headerlink" title="2.4 机器学习项目全周期"></a>2.4 机器学习项目全周期</h4><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011163931188.png"></p><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011164414049.png"></p><h4 id="2-5-倾斜数据集的误差指标"><a href="#2-5-倾斜数据集的误差指标" class="headerlink" title="2.5 倾斜数据集的误差指标"></a>2.5 倾斜数据集的误差指标</h4><ul><li>精确度和召回率</li></ul><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011165618174.png"></p><ul><li>精度和召回率</li></ul><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011170439331.png"></p><ul><li>F1score 更强调P和R中较低的那个 调和平均值</li></ul><p><img src="/2024/11/14/ML/class2-week3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231011170740787.png"></p>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
      <category>ML</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ML</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2.2 深度学习-Tenserflow实现-吴恩达</title>
    <link href="/2024/11/13/ML/class2-week2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Tenserflow%E5%AE%9E%E7%8E%B0-%E5%90%B4%E6%81%A9%E8%BE%BE/"/>
    <url>/2024/11/13/ML/class2-week2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Tenserflow%E5%AE%9E%E7%8E%B0-%E5%90%B4%E6%81%A9%E8%BE%BE/</url>
    
    <content type="html"><![CDATA[<h2 id="Tenserflow实现"><a href="#Tenserflow实现" class="headerlink" title="Tenserflow实现"></a>Tenserflow实现</h2><h3 id="1-模型训练步骤"><a href="#1-模型训练步骤" class="headerlink" title="1. 模型训练步骤"></a>1. 模型训练步骤</h3><p><img src="/2024/11/13/ML/class2-week2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Tenserflow%E5%AE%9E%E7%8E%B0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231010125603129.png" alt="模型训练步骤"></p><h4 id="1-1-Epochs-and-batches"><a href="#1-1-Epochs-and-batches" class="headerlink" title="1.1 Epochs and batches"></a>1.1 Epochs and batches</h4><p>在上述的 <code>compile</code> 语句中，<code>epochs</code> 的数量被设置为10。这指定了整个数据集在训练过程中应该被应用10次。在训练期间，你会看到描述训练进度的输出，看起来像这样：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Epoch</span> <span class="hljs-number">1</span>/<span class="hljs-number">10</span><br><span class="hljs-attribute">6250</span>/<span class="hljs-number">6250</span><span class="hljs-meta"> [==============================] - 6s 910us/step - loss: 0.1782</span><br></code></pre></td></tr></table></figure><p>第一行 <code>Epoch 1/10</code> 描述了模型当前正在运行的是哪个训练周期。为了提高效率，训练数据集被分成了“批次”。在Tensorflow中，默认的批次大小是32。我们的扩展数据集中有200000个样本，或者6250个批次。第二行的符号 <code>6250/6250 [====</code> 描述了已经执行了哪个批次。</p><h4 id="1-2-创建模型"><a href="#1-2-创建模型" class="headerlink" title="1.2 创建模型"></a>1.2 创建模型</h4><p><img src="/2024/11/13/ML/class2-week2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Tenserflow%E5%AE%9E%E7%8E%B0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231010125701208.png"></p><h4 id="1-3-交叉熵损失函数"><a href="#1-3-交叉熵损失函数" class="headerlink" title="1.3 交叉熵损失函数"></a>1.3 交叉熵损失函数</h4><p><img src="/2024/11/13/ML/class2-week2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Tenserflow%E5%AE%9E%E7%8E%B0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231010130715345.png"></p><ul><li>回归和分类使用不同的损失代价函数</li></ul><h4 id="1-4-梯度下降"><a href="#1-4-梯度下降" class="headerlink" title="1.4 梯度下降"></a>1.4 梯度下降</h4><p><img src="/2024/11/13/ML/class2-week2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Tenserflow%E5%AE%9E%E7%8E%B0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231010130841602.png"></p><p>多层感知器：多层神经网路</p><h3 id="2-激活函数"><a href="#2-激活函数" class="headerlink" title="2. 激活函数"></a>2. 激活函数</h3><h4 id="2-1-ReLU-Activation"><a href="#2-1-ReLU-Activation" class="headerlink" title="2.1 ReLU Activation"></a>2.1 ReLU Activation</h4><p>This week, a new activation was introduced, the Rectified Linear Unit (ReLU).</p><p>𝑎&#x3D;𝑚𝑎𝑥(0,𝑧) </p><p><img src="/2024/11/13/ML/class2-week2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Tenserflow%E5%AE%9E%E7%8E%B0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231010204558837.png" alt="ReLU"></p><p><img src="/2024/11/13/ML/class2-week2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Tenserflow%E5%AE%9E%E7%8E%B0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231010204715345.png"></p><ul><li><p>二分类问题，sigmoid激活函数是最自然的选择，输出层使用</p></li><li><p>回归模型，输出有正有负，预测明天的股票价格，输出层使用线性激活函数</p></li><li><p>回归模型，输出为非负，预测房屋价格，非负，输出层选择ReLU函数</p></li><li><p>隐藏层选择Relu函数，ReLU计算速度更快，效率高，但事实证明更重要的第二个原因是ReLU函数仅在图形的一部分变平;左边这里<br>是完全平坦的，而sigmoid激活函数，它在两个地方变得平坦。梯度下降就会很慢，减慢学习速度</p></li><li><p>为什么要使用激活函数？</p><ul><li>若所有层都是用线性激活函数，那就变成了线性回归</li></ul></li></ul><h3 id="3-多分类问题"><a href="#3-多分类问题" class="headerlink" title="3. 多分类问题"></a>3. 多分类问题</h3><h4 id="3-1-Softmax函数"><a href="#3-1-Softmax函数" class="headerlink" title="3.1 Softmax函数"></a>3.1 Softmax函数</h4><p><img src="/2024/11/13/ML/class2-week2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Tenserflow%E5%AE%9E%E7%8E%B0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231010212144511.png"></p><h4 id="3-2-代价函数"><a href="#3-2-代价函数" class="headerlink" title="3.2 代价函数"></a>3.2 代价函数</h4><p><img src="/2024/11/13/ML/class2-week2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Tenserflow%E5%AE%9E%E7%8E%B0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231010212557352.png"></p><p><img src="/2024/11/13/ML/class2-week2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Tenserflow%E5%AE%9E%E7%8E%B0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231010220105018.png"></p><h4 id="3-3-Tenserflow-实现"><a href="#3-3-Tenserflow-实现" class="headerlink" title="3.3 Tenserflow 实现"></a>3.3 Tenserflow 实现</h4><p><img src="/2024/11/13/ML/class2-week2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Tenserflow%E5%AE%9E%E7%8E%B0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231010220327241.png"></p><h4 id="3-4-改进实现"><a href="#3-4-改进实现" class="headerlink" title="3.4 改进实现"></a>3.4 改进实现</h4><p>避免计算过程中出现过大或者过小值造成计算错误，改进方法在计算过程中进行了重新排列</p><p><img src="/2024/11/13/ML/class2-week2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Tenserflow%E5%AE%9E%E7%8E%B0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231010221115720.png"></p><p><img src="/2024/11/13/ML/class2-week2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Tenserflow%E5%AE%9E%E7%8E%B0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231010221418604.png"></p><p><img src="/2024/11/13/ML/class2-week2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Tenserflow%E5%AE%9E%E7%8E%B0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231010221520301.png"></p><p><img src="/2024/11/13/ML/class2-week2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Tenserflow%E5%AE%9E%E7%8E%B0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231010221537117.png"></p><h3 id="4-多标签分类"><a href="#4-多标签分类" class="headerlink" title="4. 多标签分类"></a>4. 多标签分类</h3><p>一个神经网络同时检测多个目标</p><h3 id="5-更快的训练方法"><a href="#5-更快的训练方法" class="headerlink" title="5. 更快的训练方法"></a>5. 更快的训练方法</h3><h4 id="5-1-Adam算法"><a href="#5-1-Adam算法" class="headerlink" title="5.1 Adam算法"></a>5.1 Adam算法</h4><p>自动调节α</p><p><img src="/2024/11/13/ML/class2-week2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Tenserflow%E5%AE%9E%E7%8E%B0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231010231015869.png"></p><p><img src="/2024/11/13/ML/class2-week2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Tenserflow%E5%AE%9E%E7%8E%B0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231010231157191.png"></p><h3 id="6-其他的网络层"><a href="#6-其他的网络层" class="headerlink" title="6. 其他的网络层"></a>6. 其他的网络层</h3><p>密集层</p><p>卷积层</p><ul><li><p>更快的计算</p></li><li><p>需要更少的训练数据，不太会过拟合</p></li></ul><p><img src="/2024/11/13/ML/class2-week2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Tenserflow%E5%AE%9E%E7%8E%B0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231010231710233.png"></p><h3 id="7-计算图"><a href="#7-计算图" class="headerlink" title="7. 计算图"></a>7. 计算图</h3><p><img src="/2024/11/13/ML/class2-week2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Tenserflow%E5%AE%9E%E7%8E%B0-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231010235541548.png"></p>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
      <category>ML</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ML</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2.1 深度学习-神经网络-吴恩达</title>
    <link href="/2024/11/13/ML/class2-week1-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%90%B4%E6%81%A9%E8%BE%BE/"/>
    <url>/2024/11/13/ML/class2-week1-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%90%B4%E6%81%A9%E8%BE%BE/</url>
    
    <content type="html"><![CDATA[<h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><ul><li><p>输入层 输入为特征向量</p></li><li><p>隐藏层</p></li><li><p>输出层</p></li></ul><p><strong>Tensorflow and Keras</strong>  </p><ul><li>TensorFlow 是由谷歌开发的一个机器学习包。2019年，谷歌将 Keras 集成到 TensorFlow 中，并发布了 TensorFlow 2.0。Keras 是由 François Chollet 独立开发的框架，它为 TensorFlow 创建了一个简单、以层为中心的接口。本课程将使用 Keras 接口。</li></ul><h3 id="前向传播算法"><a href="#前向传播算法" class="headerlink" title="前向传播算法"></a>前向传播算法</h3><p><img src="/2024/11/13/ML/class2-week1-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231009222124079.png"></p><ul><li><p>从左到右向前计算，称为前向传播。</p></li><li><p>离输出层越近，隐藏层神经元越少。</p></li></ul><p><img src="/2024/11/13/ML/class2-week1-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231009222647437.png"></p><ul><li><p>两个特征，第一个隐藏层有三个神经元，激活函数为sigmoid，输出为a1，第二层同理；</p></li><li><p>输入向量要写成二维矩阵形式 x &#x3D; np.array([[200,17]])  1x2矩阵。</p></li></ul><p><img src="/2024/11/13/ML/class2-week1-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231009224920509.png"></p><p><img src="/2024/11/13/ML/class2-week1-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%90%B4%E6%81%A9%E8%BE%BE/image-20231009224946845.png"></p><ul><li>将权重拟合到数据（反向传播）如果数据被归一化，那么这个过程将会进行得更快。</li></ul>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
      <category>ML</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ML</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>1.3 有监督机器学习回归和分类-逻辑回归-吴恩达</title>
    <link href="/2024/11/13/ML/class1-week3-%E6%9C%89%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9B%9E%E5%BD%92%E5%92%8C%E5%88%86%E7%B1%BB-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    <url>/2024/11/13/ML/class1-week3-%E6%9C%89%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9B%9E%E5%BD%92%E5%92%8C%E5%88%86%E7%B1%BB-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/</url>
    
    <content type="html"><![CDATA[<h2 id="Week3-逻辑回归"><a href="#Week3-逻辑回归" class="headerlink" title="Week3 逻辑回归"></a>Week3 逻辑回归</h2><h3 id="1-二元分类"><a href="#1-二元分类" class="headerlink" title="1. 二元分类"></a>1. 二元分类</h3><p>只有两种可能输出的分类问题称为二元分类。</p><h3 id="2-sigmoid-函数"><a href="#2-sigmoid-函数" class="headerlink" title="2. sigmoid 函数"></a>2. sigmoid 函数</h3><p><img src="/2024/11/13/ML/class1-week3-%E6%9C%89%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9B%9E%E5%BD%92%E5%92%8C%E5%88%86%E7%B1%BB-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/image-20231008173829773.png"></p><p><img src="/2024/11/13/ML/class1-week3-%E6%9C%89%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9B%9E%E5%BD%92%E5%92%8C%E5%88%86%E7%B1%BB-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/image-20231008173915794.png" alt="sigmoid"></p><p><img src="/2024/11/13/ML/class1-week3-%E6%9C%89%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9B%9E%E5%BD%92%E5%92%8C%E5%88%86%E7%B1%BB-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/image-20241113221925070.png"></p><p>输入特征，输出0到1</p><h3 id="3-决策边界"><a href="#3-决策边界" class="headerlink" title="3. 决策边界"></a>3. 决策边界</h3><p>线性or非线性</p><h3 id="4-代价函数"><a href="#4-代价函数" class="headerlink" title="4. 代价函数"></a>4. 代价函数</h3><p>平方误差成本函数不是逻辑回归的理想成本函数，常用的是对数损失函数。</p><p><img src="/2024/11/13/ML/class1-week3-%E6%9C%89%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9B%9E%E5%BD%92%E5%92%8C%E5%88%86%E7%B1%BB-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/image-20231008205513401.png" alt="squared error cost"></p><p><img src="/2024/11/13/ML/class1-week3-%E6%9C%89%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9B%9E%E5%BD%92%E5%92%8C%E5%88%86%E7%B1%BB-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/image-20231008205613800.png" alt="凸和非凸"></p><p><img src="/2024/11/13/ML/class1-week3-%E6%9C%89%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9B%9E%E5%BD%92%E5%92%8C%E5%88%86%E7%B1%BB-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/image-20231008205638121.png" alt="image-20231008205638121"></p><p><img src="/2024/11/13/ML/class1-week3-%E6%9C%89%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9B%9E%E5%BD%92%E5%92%8C%E5%88%86%E7%B1%BB-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/image-20231008205807667.png" alt="logistic loss function"></p><p>请记住，损失函数衡量的是你在一个训练样例上的表现如何，它是通过总结你随后获得的所有训练样例的损失，成本函数衡量你在整个训练集上的表现。</p><p><img src="/2024/11/13/ML/class1-week3-%E6%9C%89%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9B%9E%E5%BD%92%E5%92%8C%E5%88%86%E7%B1%BB-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/image-20231008210426343.png" alt="image-20231008210426343"></p><p>整体成本函数为凸函数，可以获得全局最小值</p><p>简化损失函数</p><p><img src="/2024/11/13/ML/class1-week3-%E6%9C%89%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9B%9E%E5%BD%92%E5%92%8C%E5%88%86%E7%B1%BB-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/image-20231008211105952.png" alt="image-20231008211105952"></p><p>代价函数</p><p><img src="/2024/11/13/ML/class1-week3-%E6%9C%89%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9B%9E%E5%BD%92%E5%92%8C%E5%88%86%E7%B1%BB-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/image-20231008211415275.png" alt="image-20231008211415275"></p><p>使用最大似然估计推导出来，是凸函数。</p><h3 id="5-梯度下降"><a href="#5-梯度下降" class="headerlink" title="5. 梯度下降"></a>5. 梯度下降</h3><p><img src="/2024/11/13/ML/class1-week3-%E6%9C%89%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9B%9E%E5%BD%92%E5%92%8C%E5%88%86%E7%B1%BB-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/image-20231008211755913.png" alt="image-20231008211755913"></p><p><img src="/2024/11/13/ML/class1-week3-%E6%9C%89%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9B%9E%E5%BD%92%E5%92%8C%E5%88%86%E7%B1%BB-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/image-20231008211932119.png" alt="image-20231008211932119"></p><p><img src="/2024/11/13/ML/class1-week3-%E6%9C%89%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9B%9E%E5%BD%92%E5%92%8C%E5%88%86%E7%B1%BB-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/image-20231008211950319.png" alt="image-20231008211950319"></p><p>Same concepts:</p><ul><li>Monitor gradient descent(learning curve)</li><li>Vectorized implementation</li><li>Feature scaling</li></ul><h3 id="6-过拟合与欠拟合"><a href="#6-过拟合与欠拟合" class="headerlink" title="6. 过拟合与欠拟合"></a>6. 过拟合与欠拟合</h3><ul><li><p>欠拟合：高偏差 high bias  Does not fit thetraining set well</p></li><li><p>过拟合：高方差 high variance Fits the training setextremely well</p></li></ul><h3 id="7-解决过拟合"><a href="#7-解决过拟合" class="headerlink" title="7. 解决过拟合"></a>7. 解决过拟合</h3><ul><li><p>收集更多的训练样本</p></li><li><p>选择特征   select features to include&#x2F;exclude</p></li><li><p>正则化 Regularization 正则化是一种更温和地减少某些特征影响的方法，而不用像彻底消除它那样严厉。</p></li><li><p>那么正则化的作用是，它可以让你保留所有特征，但它们只是防止特征产生过大的影响，而这有时会导致过度拟合。</p></li></ul><h3 id="8-正则化-Regularization"><a href="#8-正则化-Regularization" class="headerlink" title="8. 正则化 Regularization"></a>8. 正则化 Regularization</h3><p>λ正则化参数</p><p><img src="/2024/11/13/ML/class1-week3-%E6%9C%89%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9B%9E%E5%BD%92%E5%92%8C%E5%88%86%E7%B1%BB-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/image-20231008223908932.png" alt="image-20231008223908932"></p><p>正则化线性回归</p><p><img src="/2024/11/13/ML/class1-week3-%E6%9C%89%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9B%9E%E5%BD%92%E5%92%8C%E5%88%86%E7%B1%BB-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/image-20231008224030737.png" alt="image-20231008224030737"></p><p>梯度下降</p><p><img src="/2024/11/13/ML/class1-week3-%E6%9C%89%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9B%9E%E5%BD%92%E5%92%8C%E5%88%86%E7%B1%BB-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/image-20231008224109310.png" alt="image-20231008224109310"></p><p>正则化逻辑回归</p><h1 id><a href="#" class="headerlink" title></a><img src="/2024/11/13/ML/class1-week3-%E6%9C%89%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9B%9E%E5%BD%92%E5%92%8C%E5%88%86%E7%B1%BB-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/image-20231008225551317.png" alt="image-20231008225551317"></h1>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
      <category>ML</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ML</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于演员-评论家框架的层次化多智能体协同决策方法</title>
    <link href="/2024/11/12/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1%E5%88%86%E9%85%8D/%E5%9F%BA%E4%BA%8E%E6%BC%94%E5%91%98-%E8%AF%84%E8%AE%BA%E5%AE%B6%E6%A1%86%E6%9E%B6%E7%9A%84%E5%B1%82%E6%AC%A1%E5%8C%96%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%8D%8F%E5%90%8C%E5%86%B3%E7%AD%96%E6%96%B9%E6%B3%95/"/>
    <url>/2024/11/12/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1%E5%88%86%E9%85%8D/%E5%9F%BA%E4%BA%8E%E6%BC%94%E5%91%98-%E8%AF%84%E8%AE%BA%E5%AE%B6%E6%A1%86%E6%9E%B6%E7%9A%84%E5%B1%82%E6%AC%A1%E5%8C%96%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%8D%8F%E5%90%8C%E5%86%B3%E7%AD%96%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h1><p>这篇文章的主要内容是提出了一种基于演员-评论家（Actor-Critic，AC）框架的层次化多智能体协同决策方法，旨在解决复杂作战环境下多智能体协同决策中的任务分配不合理和决策一致性较差的问题。该方法通过将决策过程分为不同层次，并使用AC框架来实现智能体之间的信息交流和决策协同，以提高决策效率和战斗力。在高层次，顶层智能体制定任务决策，将总任务分解并分配给底层智能体。在低层次，底层智能体根据子任务进行动作决策，并将结果反馈给高层次。</p><h1 id="研究方法和算法实现："><a href="#研究方法和算法实现：" class="headerlink" title="研究方法和算法实现："></a>研究方法和算法实现：</h1><div align="center"><img src="/2024/11/12/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1%E5%88%86%E9%85%8D/%E5%9F%BA%E4%BA%8E%E6%BC%94%E5%91%98-%E8%AF%84%E8%AE%BA%E5%AE%B6%E6%A1%86%E6%9E%B6%E7%9A%84%E5%B1%82%E6%AC%A1%E5%8C%96%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%8D%8F%E5%90%8C%E5%86%B3%E7%AD%96%E6%96%B9%E6%B3%95/image-20241112210938443.png" alt="image-20241112210938443" style="zoom:40%;" align="center"></div><ol><li><strong>决策层次划分：</strong><ul><li>高层次（High Level, HL）：顶层智能体负责制定任务决策，将总任务分解并分配给底层智能体。</li><li>低层次（Low Level, LL）：底层智能体根据子任务进行动作决策，并将结果反馈给高层次。</li></ul></li><li><strong>状态空间和动作空间的分割：</strong><ul><li>根据层级关系对状态空间和指令空间进行分割，HL决策针对全局作战态势信息下达宏观作战指令，LL决策对执行宏观作战指令的作战编组进行动作操控。</li></ul></li><li><strong>上层任务分解</strong><ul><li>给定总任务<em>M</em>，拆分成子任务集{𝑀0,𝑀1,⋯,𝑀𝑖}</li><li>每一个子任务有任务类型、任务时间、任务状态和作战单元类型，可用one-hot独热码<ul><li>任务类型：主要分为打击任务和巡逻任务，打击任务包含对空拦截、对陆打击，巡逻任务包含空战巡逻、反地面战巡逻</li><li>任务时间：做离散化处理，用时刻𝑇1和时刻𝑇2来表示</li><li>任务状态：启动、未启动</li><li>作战单元：导弹驱逐舰和轰炸机</li></ul></li><li>在根据想定场景设计出子任务后，HL需要根据任务类型规划出任务启动时间，并进一步确定任务的启动次序。</li></ul></li><li><strong>奖惩函数设计：</strong><ul><li>高层智能体只需要聚焦于 子任务选择是否合适，因此高层智能体的奖励函数HL<del>r</del>设计为当任务合适时给予正奖励回报，反之则为负奖励回报。本文中根据全局任务是否完成判断子任务选择是否正确。</li></ul></li><li><strong>基于AC框架的层次化多智能体算法框架：</strong><ul><li>离策略修正的层次化学习(Hierarchical  reinforcement learning with off-policy correction,  HIRO)[31]算法是一种使用两层策略结构来解决复杂强化学习问题的一种单智能体算法，核心思想是高层策略提出目标，低层策略完成这一目标。</li><li>采用部分可观察马尔可夫决策过程（POMDP）对环境进行建模。</li><li>利用深度确定性策略梯度（Deep Deterministic Policy Gradient, DDPG）算法作为基础，结合多智能体深度强化学习，形成了Hierarchical Multi-Agent Actor-Critic（HMaAC）算法。</li></ul></li><li><strong>HMaAC算法设计：</strong><ul><li>初始化顶层和底层的Critic网络和Actor网络，以及经验回放缓冲池。</li><li>通过采样和最小化损失函数更新Critic网络，通过策略梯度更新Actor网络。</li><li>引入熵约束的概念，最大化策略的熵以学习设置合适的子目标。</li></ul></li><li><strong>仿真环境与仿真结果：</strong><ul><li>使用联合作战仿真推演平台作为实验验证环境，进行了2v2、4v4、6v6等不同规模的作战场景实验。</li><li>实验结果显示，HMaAC算法在多种复杂作战场景下均取得了较好的性能，展现了其在提升军事作战协同决策能力方面的潜力。</li></ul></li><li><strong>网络结构设计和训练参数：</strong><ul><li>设计了上层和下层的神经网络结构，均使用3层全连接层，使用ReLU和Tanh作为激活函数。</li><li>设定了一系列超参数，如最大episode数量、批处理参数、熵正则项系数等。</li></ul></li></ol><p><img src="/2024/11/12/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1%E5%88%86%E9%85%8D/%E5%9F%BA%E4%BA%8E%E6%BC%94%E5%91%98-%E8%AF%84%E8%AE%BA%E5%AE%B6%E6%A1%86%E6%9E%B6%E7%9A%84%E5%B1%82%E6%AC%A1%E5%8C%96%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%8D%8F%E5%90%8C%E5%86%B3%E7%AD%96%E6%96%B9%E6%B3%95/image-20241113205648783.png"></p><ol><li><strong>训练结果分析：</strong><ul><li>对比了HMaAC算法和MADDPG算法在2v2仿真场景中的表现，HMaAC算法在奖励值和收敛速度上优于MADDPG算法。</li></ul></li></ol><p>文章最后指出，尽管HMaAC算法在实验中表现出色，但仍需在实地测试和实战演练中进一步验证其可行性和有效性，同时探讨在更复杂多样化作战环境中的适应性和鲁棒性。</p><p>[1]傅妍芳,雷凯麟,魏佳宁,等.基于演员-评论家框架的层次化多智能体协同决策方法[J].兵工学报,2024,45(10):3385-3396.</p>]]></content>
    
    
    <categories>
      
      <category>科研</category>
      
      <category>多智能体强化学习任务分配</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RL</tag>
      
      <tag>科研</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>1.2 因特网概述</title>
    <link href="/2024/11/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/1.2%E5%9B%A0%E7%89%B9%E7%BD%91%E6%A6%82%E8%BF%B0/"/>
    <url>/2024/11/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/1.2%E5%9B%A0%E7%89%B9%E7%BD%91%E6%A6%82%E8%BF%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="1-2-因特网概述"><a href="#1-2-因特网概述" class="headerlink" title="1.2 因特网概述"></a>1.2 因特网概述</h1><h2 id="1-网络，互联网和因特网"><a href="#1-网络，互联网和因特网" class="headerlink" title="1. 网络，互联网和因特网"></a>1. 网络，互联网和因特网</h2><ul><li>网络是由若干结点和链接这些结点的链路组成</li><li>多个网络通过路由器互连起来，构成一个覆盖范围更大的网路，称为互联网</li><li>因特网是世界上最大的互联网络，连接在因特网上的计算机称为主机</li></ul><h3 id="1-1-internet和Internet的区别"><a href="#1-1-internet和Internet的区别" class="headerlink" title="1.1 internet和Internet的区别"></a>1.1 internet和Internet的区别</h3><ol><li>internet(互联网或互连网)是一个通用名词，它泛指由多个计算机网络互连而成的网络。在这些网络之间的通信协议可以是任意的。</li><li>Internet(因特网)则是一个专用名词，它指当前全球最大的、开放的、由众多网络相互连接而成的特定计算机网络，它采用TCPP协议族作为通信的规则，其前身是美国的ARPANET。</li></ol><h2 id="2-因特网服务提供者ISP-Internet-Service-Provider"><a href="#2-因特网服务提供者ISP-Internet-Service-Provider" class="headerlink" title="2. 因特网服务提供者ISP(Internet Service Provider)"></a>2. 因特网服务提供者ISP(Internet Service Provider)</h2><ul><li>通过向ISP缴纳费用，拿到IP地址和通信线路，路由器等连网设备的使用权</li><li>同时，每个接入因特网的用户，也可以成为ISP，只需购买调制解调器或路由器这样的设备，让其他用户与之相连</li></ul><p><img src="/2024/11/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/1.2%E5%9B%A0%E7%89%B9%E7%BD%91%E6%A6%82%E8%BF%B0/image-20241115201435974.png" alt="image-20241115201435974"></p><h3 id="2-1-基于ISP的三层结构的因特网"><a href="#2-1-基于ISP的三层结构的因特网" class="headerlink" title="2.1 基于ISP的三层结构的因特网"></a>2.1 基于ISP的三层结构的因特网</h3><ul><li>第一层：国际性区域</li><li>第二层：区域性或国家性覆盖规模</li><li>第三层：本地ISP</li></ul><p><img src="/2024/11/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/1.2%E5%9B%A0%E7%89%B9%E7%BD%91%E6%A6%82%E8%BF%B0/image-20241115201638639.png" alt="image-20241115201638639"></p><h2 id="3-因特网的标准化工作"><a href="#3-因特网的标准化工作" class="headerlink" title="3. 因特网的标准化工作"></a>3. 因特网的标准化工作</h2><ol><li><p>因特网的标准化工作对因特网的发展起到了非常重要的作用。</p></li><li><p>因特网在制定其标准上的一个很大的特点是面向公众。</p><ol><li>因特网所有的<a href="http://www.ietf.org/rfc.html">RFC(Request For Comments)技术文档</a>都可从因特网上免费下载；</li><li>任何人都可以随时用电子邮件发表对某个文档的意见或建议。</li></ol></li><li><p>因特网协会ISOC是一个国际性组织，它负责对因特网进行全面管理，以及在世界范围内促进其发展和使用。</p><ol><li>因特网体系结构委员会IAB,负责管理因特网有关协议的开发：</li><li>因特网工程部ETF，负责研究中短期工程问题，主要针对协议的开发和标准化</li><li>因特网研究部IRTF,从事理论方面的研究和开发一些需要长期考虑的问题。</li></ol></li><li><p>制订因特网的正式标准要经过以下4个阶段：</p><ol><li>因特网草案（在这个阶段还不是RFC文档）</li><li>建议标准（从这个阶段开始就成为RFC文档）<br>因特网体系结构委员会A由</li><li>草案标准</li><li>因特网标准</li></ol><blockquote><p>只有一小部分RFC文档最后才能变成因特网标准</p></blockquote></li></ol><h2 id="4-因特网的组成"><a href="#4-因特网的组成" class="headerlink" title="4. 因特网的组成"></a>4. 因特网的组成</h2><ol><li><p>边缘部分</p><blockquote><p>由所有连接在因特网上 的主机组成。这部分是用户直接使用的，用来进行通信（传送数据，音频或视频)和资源共享。</p></blockquote></li><li><p>核心部分</p><blockquote><p>由大量网络和连接这些网络的路由器组成。这部分是为边缘部分提供服务的（提供连通性和交换）</p></blockquote><ol><li><strong>路由器</strong>是实现<strong>分组交换</strong>的关键构件，任务是<strong>转发收到的分组</strong></li></ol></li></ol>]]></content>
    
    
    <categories>
      
      <category>计算机基础</category>
      
      <category>计算机网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>os</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>github+hexo 搭建个人网站</title>
    <link href="/2024/11/12/hexo/github-hexo-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/"/>
    <url>/2024/11/12/hexo/github-hexo-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/</url>
    
    <content type="html"><![CDATA[<h1 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h1><h2 id="安装准备"><a href="#安装准备" class="headerlink" title="安装准备"></a>安装准备</h2><p>Git版本：Git-2.47.0.2-64-bit</p><p>Node.js版本：node-v22.11.0-x64</p><ol><li>官网下载，一路下一步安装即可。</li></ol><p>安装完成，右键git bash here，输入</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">git --version<br>node -v<br>npm -v<br></code></pre></td></tr></table></figure><p>安装成功，可查看版本。</p><ol start="2"><li>安装hexo:</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">npm install hexo -g<br></code></pre></td></tr></table></figure><p>hexo 安装成功，输入</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo -v<br></code></pre></td></tr></table></figure><h2 id="git-配置SSH-key"><a href="#git-配置SSH-key" class="headerlink" title="git 配置SSH key"></a>git 配置SSH key</h2><ol><li>生成key</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ssh-keygen -t rsa -C <span class="hljs-string">&quot;xxx@qq.com&quot;</span><br></code></pre></td></tr></table></figure><ol start="2"><li>进入C:\用户\用户名.ssh，进入ssh文件夹，复制id_rsa.pub文件里的所有内容</li><li>打开github主页，点击个人设置，点击左侧SSH and GPG keys，点击New SSh key</li><li>标题随便起，将复制的内容粘贴到Key，点击Add SSH key</li><li>测试是否成功，在git bash中输入：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ssh -T git@github.com<br></code></pre></td></tr></table></figure><p><font style="color:rgb(83, 88, 97);">如果遇到选择，输入yes，看到成功即可。</font></p><ol start="6"><li>配置账号密码</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">git config --global user.name <span class="hljs-string">&quot;xxx&quot;</span> <span class="hljs-comment">#你的github用户名</span><br>git config --global user.email <span class="hljs-string">&quot;xxx@163.com&quot;</span> <span class="hljs-comment">#填写你的github注册邮箱</span><br></code></pre></td></tr></table></figure><ol start="7"><li>安装部署插件</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">npm install hexo-deployer-git -save<br></code></pre></td></tr></table></figure><h1 id="搭建个人博客"><a href="#搭建个人博客" class="headerlink" title="搭建个人博客"></a>搭建个人博客</h1><ol><li>新建文件夹，初始化个人博客，右键打开git bash，输入</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo init <span class="hljs-comment">#初始化</span><br></code></pre></td></tr></table></figure><ol start="2"><li>生成静态网页并预览</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo g <span class="hljs-comment"># 生成静态页面</span><br>hexo s <span class="hljs-comment"># 预览</span><br></code></pre></td></tr></table></figure><ol start="3"><li><p>打开网址即可预览</p></li><li><p>打开github 创建与用户名同名的仓库：username.github.io，并查看主分支是main or master</p></li><li><p>打开博客目录下的_config.ymal，找到对应内容并修改</p></li></ol><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-attr">deploy:</span><br>  <span class="hljs-attr">type:</span> <span class="hljs-string">git</span><br>  <span class="hljs-attr">repository:</span> <span class="hljs-string">git@github.com:username/username.github.io.git</span><br>  <span class="hljs-attr">branch:</span> <span class="hljs-string">main</span><br></code></pre></td></tr></table></figure><ol start="6"><li>发布到github</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo d<br></code></pre></td></tr></table></figure><ol start="7"><li>新建博客</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo new <span class="hljs-string">&#x27;blog-name&#x27;</span><br>hexo new title -p  <span class="hljs-string">&#x27;subdir/title&#x27;</span><br></code></pre></td></tr></table></figure><p>在source&#x2F;_post目录下可查看新建的md文件。</p><p>注：可在hexo s服务开启的状态下修改问价内容查看预览内容。</p><p>要设置其他主题，可自行查找，博主参考Fluid风格的blog <a href="https://hexo.fluid-dev.com/docs/">Hexo Fluid 用户手册</a>。</p>]]></content>
    
    
    <categories>
      
      <category>软件开发</category>
      
      <category>git</category>
      
    </categories>
    
    
    <tags>
      
      <tag>git</tag>
      
      <tag>个人博客</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>rust todo</title>
    <link href="/2024/11/12/Rust/rust/"/>
    <url>/2024/11/12/Rust/rust/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>rust</category>
      
    </categories>
    
    
    <tags>
      
      <tag>rust</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ubuntu虚拟机磁盘扩容</title>
    <link href="/2022/12/13/ubuntu/ubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%A3%81%E7%9B%98%E6%89%A9%E5%AE%B9/"/>
    <url>/2022/12/13/ubuntu/ubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%A3%81%E7%9B%98%E6%89%A9%E5%AE%B9/</url>
    
    <content type="html"><![CDATA[<h1 id="Ubuntu虚拟机磁盘空间不够，如何扩容"><a href="#Ubuntu虚拟机磁盘空间不够，如何扩容" class="headerlink" title="Ubuntu虚拟机磁盘空间不够，如何扩容"></a>Ubuntu虚拟机磁盘空间不够，如何扩容</h1><h2 id="一、软件版本"><a href="#一、软件版本" class="headerlink" title="一、软件版本"></a>一、软件版本</h2><p>1.vmware 15.5.0</p><p>2.ubuntu 20.04</p><h2 id="二、操作步骤"><a href="#二、操作步骤" class="headerlink" title="二、操作步骤"></a>二、操作步骤</h2><p>1.打开虚拟机设置，点击硬盘<br><img src="/2022/12/13/ubuntu/ubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%A3%81%E7%9B%98%E6%89%A9%E5%AE%B9/15fc8dc4f12fa5028a9388249f3af272.png" alt="在这里插入图片描述"></p><p>2.点击扩展<br><img src="/2022/12/13/ubuntu/ubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%A3%81%E7%9B%98%E6%89%A9%E5%AE%B9/03bf87f8780d1f5f0d7b6c7130f738ca.png" alt="在这里插入图片描述"></p><p>3.此处我由50G增加到70G，点击扩展<br><img src="/2022/12/13/ubuntu/ubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%A3%81%E7%9B%98%E6%89%A9%E5%AE%B9/19983adb5563d49266bf294485b59606.png" alt="在这里插入图片描述"></p><p>4.开启虚拟机</p><p>5.点击磁盘<br><img src="/2022/12/13/ubuntu/ubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%A3%81%E7%9B%98%E6%89%A9%E5%AE%B9/c8428adcd11dfe842401ab61e80d16f2.png" alt="在这里插入图片描述"></p><p>6.看到有21G的未分配的磁盘空间</p><p><img src="/2022/12/13/ubuntu/ubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%A3%81%E7%9B%98%E6%89%A9%E5%AE%B9/226cfc5dee27ecee83abb2ac08898792.png" alt="在这里插入图片描述"></p><p>7.点击扩展分区</p><p><img src="/2022/12/13/ubuntu/ubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%A3%81%E7%9B%98%E6%89%A9%E5%AE%B9/e8a7616f83cfd499830719c53a862147.png" alt="在这里插入图片描述"></p><p>8.点击设置</p><p><img src="/2022/12/13/ubuntu/ubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%A3%81%E7%9B%98%E6%89%A9%E5%AE%B9/6b93eb112dfe8bce5b66ddb825349451.png" alt="在这里插入图片描述"></p><p>9.调整大小</p><p>10.把按钮拖动到最大，点击调整大小<br><img src="/2022/12/13/ubuntu/ubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%A3%81%E7%9B%98%E6%89%A9%E5%AE%B9/64180784c7a86f2bccc1103506efefda.png" alt="在这里插入图片描述"></p><p>11.选择文件系统进行同样的操作</p><p>12.在终端使用命令 df查看</p><p><img src="/2022/12/13/ubuntu/ubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%A3%81%E7%9B%98%E6%89%A9%E5%AE%B9/c8b5025526882a778881a1c67620328d.png" alt="在这里插入图片描述"></p><p>扩容成功！！！！！！！！！</p>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ubuntu</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
